### 直译

# Preprints.org

文章

## 新解决方案对于类人双眼视觉中的3D投影

Ming Xie *，Yuhui Fang，Tingfeng Lai

发布日期：2023年10月8日

doi: 10.20944/preprints202310.0444.v1

关键词：单眼视觉；双眼视觉；前向投影；逆向投影；位移投影

# 文章

## 新解决方案对于类人双眼视觉中的3D投影

Ming Xie ${ }^{1, *}$, Yuhui Fang ${ }^{2}$ 和 Tingfeng Lai ${ }^{2}$<br>1 机械与航空工程学院，南洋理工大学，新加坡<br>2 机械工程硕士课程，南洋理工大学，新加坡<br>* 通信作者: mmxie@ntu.edu.sg; 电话: +65 98379612;

#### 摘要

人眼大约有1.2亿个杆状细胞和600万个锥状细胞。这大量的感光细胞会持续产生大量的视觉信号，这些信号流入人脑进行日常处理。然而，这些视觉信号的实时处理并不会使人脑感到任何疲劳。这一事实告诉我们，类人视觉处理过程不依赖于复杂的公式来计算深度、位移和颜色等。另一方面，人眼就像一个PTZ相机。这里，PTZ代表平移、倾斜和缩放。我们都知道，在计算机视觉中，每一组PTZ参数（即，平移、倾斜和缩放的系数）都需要专门的校准来确定相机的投影矩阵。由于人眼可以产生无限数量的PTZ参数，人脑不太可能为每只眼睛存储无限数量的校准矩阵。因此，一个有趣的问题是，是否存在更简单的计算深度和位移的公式。此外，这些公式必须是校准友好的（即，易于现场或即时处理）。在本文中，我们揭示了一个重要的发现，即类人双眼视觉系统中3D投影的新解决方案。进行双眼视觉中的3D投影的目的是进行2D数字图像坐标与3D模拟场景坐标之间的前向和逆向转换（或映射）。这些新解决方案的公式准确、易于计算、易于调整（即，可即时或即时校准）并且可以容易地通过神经系统（即，神经元网络）实现。实验结果已验证了所发现公式的有效性。

关键词：单眼视觉；双眼视觉；前向投影；逆向投影；位移投影。

## 1. 引言

我们生活在一个信号的海洋中。在所有信号中，最重要的应该是视觉信号。因此，视觉对人类的智能极其重要【1】。同样，视觉对自主机器人的智能也极其重要【2】。在过去的几十年中，已经有大量的研究活动致力于计算机视觉研究。这种研究的强度可通过提交到ICCV（即，国际计算机视觉会议）和CVPR（即，计算机视觉与模式识别国际会议）的大量会议论文数量来见证。然而，尽管研究工作持续进行，今天的计算机视觉仍远远落后于人类视觉的性能。因此，我们有必要认真分析计算机视觉和人类视觉之间的差距。

如图1所示，人眼的运动方面就像一个PTZ相机。这里，PTZ代表平移、倾斜和缩放。我们知道人眼可以进行持续的运动和缩放。这意味着人眼有无限数量的PTZ参数（即，平移、倾斜和缩放的系数）。然而，我们的视觉处理对PTZ参数的变化不敏感【3-5】。

另一方面，人眼大约有1.2亿个杆状细胞和600万个锥状细胞。这些细胞负责将光转换为视觉信号，然后由人脑处理。我们的日常经验告诉我们，尽管在实时和持续处理大量视觉信号的情况下，我们的大脑不会经历任何加热效应和疲劳。

这一观察让我们相信，在人脑内运行的视觉处理公式必须是简单的，并且适合于容易和快速地由类人脑神经系统实现【6,7】。

![图1。人眼和电子相机运动方面的比较（图片来源于互联网免费资源）](https://cdn.mathpix.com/cropped/2024_01_16_982703e8101a6fa6b936g-03.jpg?height=440&width=1128&top_left_y=431&top_left_x=430)

图1. 人眼和电子相机运动方面的比较（图片来源于互联网

免费资源）。

鉴于上述简洁的分析，我们有理由相信，计算机视觉（或机器人视觉）的未来研究方向应专注于发现和发明类似于人脑内视觉处理背后公式的原理和算法。希望，这一发现和发明的成果可以在类脑数字计算机中实现【7】。

在本文中，我们证明并验证了一个新的解决方案，将使得如汽车式机器人和仿人机器人等自主机器人能够在类人双眼视觉中进行3D投影。3D投影包括位置和位移的前向和逆向投影。

本文的组织结构如下：将在第2节描述所研究的技术问题。背景知识或相关工作将在第3节介绍。类人双眼视觉中3D投影的新解决方案及其证明将在第4节展示。验证所述新解决方案的实验结果包含在第5节中。最后，我们在第6节总结本文。

## 2. 问题陈述

我们生活在一个三维空间或场景中。同样，自主机器人也在三维空间或场景中展现其存在或活动。一般来说，一个3D场景包括一组具有全局姿态（即，位置和方向）和局部形状的实体。如果我们遵循机器人学中的惯例，场景中的每个实体都将被分配一个坐标系统（或简称为框架），这称为局部坐标系统（或简称为局部框架）。在全局坐标系统（或全局框架）内，实体的姿态由其局部坐标系统的位置和方向表示。在实体的局部坐标系统内，实体的形状可以通过三角形网格或点云表示【8】。

因此，我们日常行为或活动的成功依赖于我们感知三维空间或场景的心理能力。同样，自主机器人的成功也依赖于其感知三维空间或场景的心理能力。更具体地说，人类或自主机器人的智能依赖于外部循环的正常运作，包括感知、规划和控制，如图2所示【9,10】。

不用说，人类视觉本质上是双眼的。当然，双眼视觉赋予了人类心智以印象深刻的智能行为，这些行为由感知规划-控制循环指导。因此，我们毫不怀疑，旨在通过类人双眼视觉的指导实现自主机器人类人智能行为的研究主题是重要的【11】。

![图2。由类人双眼视觉引导的机器人手臂操纵器和自主汽车式机器人的感知、规划和控制的外部循环](https://cdn.mathpix.com/cropped/2024_01_16_982703e8101a6fa6b936g-04.jpg?height=474&width=1098&top_left_y=243&top_left_x=478)

(a) 由类人双眼视觉引导的机器人手臂操纵器

图2. 由类人双眼视觉引导的机器人手臂操纵器和自主汽车式机器人的感知、规划和控制的外部循环。

以视觉信号为输入，双眼视觉的两个重要任务是提供关于这两个一般问题的信息和知识，即：a) 看到了什么？和 b) 看到的实体在哪里？图3说明了双眼视觉系统面临的这两个相关问题。请注意，双眼视觉中的第三个流行问题是：看到的实体的形状是什么？然而，对第一个问题的解决方案也是对这第三个问题的解决方案。因此，没有必要特别强调这第三个流行问题。

![图3。类人双眼视觉系统面临的两个基本问题是：a) 看到了什么？和在哪里看到了实体？](https://cdn.mathpix.com/cropped/2024_01_16_982703e8101a6fa6b936g-04.jpg?height=662&width=1102&top_left_y=1254&top_left_x=477)

图3. 类人双眼视觉系统面临的两个基本问题是：a) 看到了什么？和在哪里看到了实体？

如图3所示，第一个问题涉及到实体检测（例如，物体检测）、实体识别（例如，物体识别）或实体分类（例如，物体分类）的问题。第二个问题涉及到2D/3D定位或2D/3D重建的问题。在本文中，所研究的问题是开发一个更好的解决方案，为第二个问题提供答案。

## 3. 相关工作

本文中所研究的问题属于计算机视觉，这是科学和工程中一个成熟的学科【12-18】。由于计算机视觉是自主机器人内部感知系统或模块的一个非常重要的部分，所研究的问题也与机器

人学相关，其中一个有趣的概念是关于正向和逆向运动学。在本节中，我们总结了机器人学和计算机视觉中的背景知识（或相关工作），这些知识构成了本文中所呈现的新解决方案的基础。

### 3.1. 运动链的概念

在机器人学【19-22】中，运动学的研究从分配局部坐标系统（或框架）给每个刚体（例如，机器人中的一个环节）开始。通过这种方式，机器人手臂操纵器中的一系列环节成为一个运动链。因此，机器人学中的运动学主题是关于研究分配给机器人手臂操纵器环节的局部坐标系统之间的运动关系。

一般来说，视觉系统必须涉及至少一个相机的使用，包括一个镜头（即，一个刚体）、一个成像传感器阵列（即，一个刚体）和一个数字图像矩阵（即，一个虚拟刚体）。此外，相机必须安装在机器人、机器或支撑地面上，每个都可以被认为是一个刚体。因此，相机应被视为一个运动链。这样，我们可以讨论相机、单眼视觉或双眼视觉的运动学。

例如，在图3中，双眼视觉系统可以被视为两个单眼视觉系统的总和。每个单眼视觉系统由单个相机组成。如果我们观察左相机，我们可以看到其运动链，其中包括以下运动变换：从世界框架到左相机框架的变换，从左相机框架到模拟图像框架的变换，以及从模拟图像框架到数字图像框架的变换。

### 3.2. 相机的前向投影矩阵

单个相机是单眼视觉的基础。在我们能够理解单眼视觉的2D前向和逆向投影的细节之前，我们需要了解相机前向投影矩阵的细节。

参考图4。使用运动链的术语，相机矩阵的推导从参考框架到相机框架的变换开始。如果点Q相对于参考框架的坐标为$(X, Y, Z)$，则相同点Q相对于相机框架的坐标$(X_{c}, Y_{c}, Z_{c})$将是【12】：

$$
\left[\begin{array}{c}
X_{c} \\
Y_{c} \\
Z_{c} \\
1
\end{array}\right]=\left[\begin{array}{cccc}
r_{11} & r_{12} & r_{13} & t_{x} \\
r_{21} & r_{22} & r_{23} & t_{y} \\
r_{31} & r_{32} & r_{33} & t_{z} \\
0 & 0 & 0 & 1
\end{array}\right] \cdot\left[\begin{array}{c}
X \\
Y \\
Z \\
1
\end{array}\right]
$$

其中旋转矩阵$\left\{r_{ij}, i \in[1,3], j \in[1,3]\right\}$代表参考框架相对于相机框架的方向，平移向量$\left(t_{x}, t_{y}, t_{z}\right)^{t}$代表参考框架原点相对于相机框架的位置。

![图4。单个相机是单眼视觉的基础](https://cdn.mathpix.com/cropped/2024_01_16_982703e8101a6fa6b936g-05.jpg?height=580&width=1148&top_left_y=1840&top_left_x=454)

图4. 单个相机是单眼视觉的基础。

在相机框架内，点Q的坐标$(X_{c}, Y_{c}, Z_{c})$到点q的模拟图像坐标$(x, y)^{t}$的转换将是：

$$
\left[\begin{array}{c}
s \cdot x \\
s \cdot y \\
s
\end{array}\right]=\left[\begin{array}{cccc}
f & 0 & 0 & 0 \\
0 & f & 0 & 0 \\
0 & 0 & 1 & 0
\end{array}\right] \cdot\left[\begin{array}{c}
X_{c} \\
Y_{c} \\
Z_{c} \\
1
\end{array}\right]
$$

其中$f$是相机的焦距，$s$是一个缩放因子。

默认情况下，我们使用数字相机。因此，模拟图像被转换为相应的数字图像。这样的数字化过程导致从模拟图像框架到数字图像框架的进一步转换。这一转换由以下方程描述：

$$
\left[\begin{array}{c}
s \cdot u \\
s \cdot v \\
s
\end{array}\right]=\left[\begin{array}{ccc}
\frac{1}{\Delta u} & 0 & u_{0} \\
0 & \frac{1}{\Delta v} & v_{0} \\
0 & 0 & 1
\end{array}\right] \cdot\left[\begin{array}{c}
S \cdot x \\
s \cdot y \\
s
\end{array}\right]
$$

其中$(u, v)^{t}$是点q的数字图像坐标，$\Delta u$是像素的宽度（即，数字图像在水平方向上的像素密度），$\Delta v$是像素

的高度（即，数字图像在垂直方向上的像素密度），$(u_{0}, v_{0})^{t}$是光轴（即，相机框架的Z轴）与图像平面的交点的数字图像坐标（注意：这个点也称为相机的主点）。

现在，通过将方程1和方程2代入方程3，我们将能够得到以下方程【16】：

$$
\left[\begin{array}{c}
s \cdot u \\
s \cdot v \\
s
\end{array}\right]=C_{f} \cdot\left[\begin{array}{c}
X \\
Y \\
Z \\
1
\end{array}\right]
$$

其中

$$
C_{f}=\left[\begin{array}{cccc}
\frac{f}{\Delta u} & 0 & u_{0} & 0 \\
0 & \frac{f}{\Delta v} & v_{0} & 0 \\
0 & 0 & 1 & 0
\end{array}\right] \cdot\left[\begin{array}{cccc}
r_{11} & r_{12} & r_{13} & t_{x} \\
r_{21} & r_{22} & r_{23} & t_{y} \\
r_{31} & r_{32} & r_{33} & t_{z} \\
0 & 0 & 0 & 1
\end{array}\right]
$$

其中矩阵$C_{f}$称为相机的前向投影矩阵，这是一个$3 \times 4$的矩阵。

### 3.3. 单眼视觉的3D前向投影

单眼视觉系统使用单个相机。其运动链与图4所示的相同。最重要的是，方程4描述了单眼视觉系统的3D前向投影，其中3D坐标$(X, Y, Z)^{t}$被投影到2D数字图像坐标$(u, v)^{t}$上。

### 3.4. 单眼视觉的3D逆向投影

从纯数学的角度来看，方程4可以重写为以下形式：

$$
\left[\begin{array}{c}
k \cdot X \\
k \cdot Y \\
k \cdot Z \\
k
\end{array}\right]=C_{i} \cdot\left[\begin{array}{l}
u \\
v \\
1
\end{array}\right]
$$

其中

$$
C_{i}=\left(C_{f}^{t} \cdot C_{f}\right)^{-1} \cdot C_{f}^{t}
$$

且$k=1 / s$。

理论上，方程6描述了单眼视觉系统的3D逆向投影。在实践中，方程6可以用一个人工神经网络图形表示，该网络作为预测器。

输入层由$(u, v, 1)^{t}$组成，输出层由$(X, Y, Z)^{t}$组成。矩阵$C_{i}$包含权重系数。因此，对我们来说很明显，不同的矩阵$C_{i}$将使得在不同平面表面上预测坐标$(X, Y, Z)^{t}$成为可能。最重要的是，矩阵$C_{i}$可以通过自上而下的校准过程或自下而上的调整（即，优化）过程获得。因此，方程6是一个很好的例子，帮助我们理解机器学习和机器校准（或调整）之间的区别。

尽管$C_{i}$是一个$4 \times 3$的矩阵，但使用方程6通常无法从数字图像中的2D索引坐标$(u, v)^{t}$（即，$u$是列索引而$v$是行索引）计算出模拟场景中的3D坐标$(X, Y, Z)^{t}$。然而，方程6背后的哲学启发我们发现了一个类似的，但非常有用的，双眼视觉的3D逆向投影，这将在第4节中描述。

## 3.5. 单眼视觉的2D前向投影

参考图4。如果我们考虑参考框架的OXY平面上的点或位置，方程4中的$Z$坐标变为零。因此，方程4可以重写为以下形式：

$$
\left[\begin{array}{c}
s \cdot u \\
s \cdot v \\
s
\end{array}\right]=M_{f} \cdot\left[\begin{array}{l}
X \\
Y \\
1
\end{array}\right]
$$

其中矩阵$M_{f}$是在移除其第三列后的矩阵$C_{f}$的版本，因为$Z$等于零。显然，矩阵$M_{f}$是一个$2 \times 2$的矩阵，并且是可逆的。如图8所示，方程8实际上描述了从参考框架平面上的坐标$(X, Y)^{t}$到单眼视觉的数字图像坐标$(u, v)^{t}$的2D前向投影。

## 3.6. 单眼视觉的2D逆向投影

现在，通过反转方程8，我们可以轻松得到以下结果：

$$
\left[\begin{array}{c}
k \cdot X \\
k \cdot Y \\
k
\end{array}\right]=M_{i} \cdot\left[\begin{array}{l}
u \\
v \\
1
\end{array}\right]
$$

其中

$$
M_{i}=\left(M_{f}^{t} \cdot M_{f}\right)^{-1} \cdot M_{f}^{t}
$$

其中矩阵$M_{i}$也是一个$2 \times 2$的矩阵。

不言而喻，方

程8和方程9完全描述了单眼视觉系统的2D前向和逆向投影，如图5所示。

![图5。单眼视觉系统2D前向和逆向投影的完整说明](https://cdn.mathpix.com/cropped/2024_01_16_982703e8101a6fa6b936g-07.jpg?height=594&width=1125&top_left_y=1990&top_left_x=471)

图5. 单眼视觉系统2D前向和逆向投影的完整说明。

### 3.7. 从双眼视觉计算3D坐标的教科书解决方案

如上所述，在理论上，一般情况下不可能从数字图像中的2D索引坐标计算出场景中的3D坐标。这一事实由方程4和方程6证明，因为缺少一个约束。

众所周知，如果我们想要一般地确定场景中的3D坐标，我们需要添加一个额外的约束。添加一个额外约束的流行解决方案是引入第二个相机。这种解决方案导致了所谓的双眼视觉系统，如图3所示。

现在，通过应用方程4到图3，我们将得到以下两个关系：

$$
\left[\begin{array}{c}
s_{l} \cdot u_{l} \\
s_{l} \cdot v_{l} \\
s_{l}
\end{array}\right]=C_{f}^{l} \cdot\left[\begin{array}{c}
X \\
Y \\
Z \\
1
\end{array}\right]
$$

和

$$
\left[\begin{array}{c}
s_{r} \cdot u_{r} \\
s_{r} \cdot v_{r} \\
s_{r}
\end{array}\right]=C_{f}^{r} \cdot\left[\begin{array}{c}
X \\
Y \\
Z \\
1
\end{array}\right]
$$

其中$C_{f}^{l}=\left\{c_{ij}^{l}, i \in[1,3], j \in[1,4]\right\}$和$C_{f}^{r}=\left\{c_{ij}^{r}, i \in[1,3], j \in[1,4]\right\}$分别是左右相机的前向投影矩阵，$(u_{l}, v_{l})^{t}$是点b的索引坐标，b是点Q在左相机内的图像，$(u_{r}, v_{r})^{t}$是点a的索引坐标，a是点Q在右相机内的图像。

如果定义矩阵$U$和向量$V$如下：

$$
U=\left[\begin{array}{lll}
\left(c_{11}^{l}-c_{31}^{l} \cdot u_{l}\right) & \left(c_{12}^{l}-c_{32}^{l} \cdot u_{l}\right) & \left(c_{13}^{l}-c_{33}^{l} \cdot u_{l}\right) \\
\left(c_{21}^{l}-c_{31}^{l} \cdot v_{l}\right) & \left(c_{22}^{l}-c_{32}^{l} \cdot v_{l}\right) & \left(c_{23}^{l}-c_{33}^{l} \cdot v_{l}\right) \\
\left(c_{11}^{r}-c_{31}^{r} \cdot u_{r}\right) & \left(c_{12}^{r}-c_{32}^{r} \cdot u_{r}\right) & \left(c_{13}^{r}-c_{33}^{r} \cdot u_{r}\right) \\
\left(c_{21}^{r}-c_{31}^{r} \cdot v_{r}\right) & \left(c_{22}^{r}-c_{32}^{r} \cdot v_{r}\right) & \left(c_{23}^{r}-c_{33}^{r} \cdot v_{r}\right)
\end{array}\right]
$$

和

$$
V=\left[\begin{array}{l}
u_{l}-c_{14}^{l} \\
v_{l}-c_{24}^{l} \\
u_{r}-c_{14}^{r} \\
v_{r}-c_{24}^{r}
\end{array}\right]
$$

在方程11和方程12中消除$s_{l}$和$s_{r}$，然后将结果方程相加，将产生以下结果：

$$
U \cdot\left[\begin{array}{l}
X \\
Y \\
Z
\end{array}\right]=V
$$

最后，矩阵$U$的伪逆将导致以下公式，用于计算3D坐标$(X, Y, Z)^{t}$：

$$
\left[\begin{array}{l}
X \\
Y \\
Z
\end{array}\right]=\left(U^{t} \cdot U\right)^{-1}\left(U^{t} \cdot V\right)
$$

方程16是计算3D坐标的教科书解决方案，如果给定一对匹配的$\left\{\left(u_{l}, v_{l}\right),\left(u_{r}, v_{r}\right)\right\}$。

显然，方程16告诉我们，计算每组$3D$坐标需要大量的计算资源。如果双眼视觉系统中的图像包含大量像素，这样的计算将消耗大量能源。

然而，我们的眼睛不会使我们的大脑感到疲劳。当然，必须有一种更简单的方法来精确计算类人双眼视觉系统内的$3D$坐标。我们将在下一节中介绍一个有趣的解决方案，这不需要昂贵的计算资源，因此将消耗更少的能量。

## 4. 类人双眼视觉中3D投影的方程

第3节中描述的方程8和方程9表明，单眼视觉系统

在2D数字图像和2D平面表面之间具有前向和逆向投影。特别是，这两个方程不需要昂贵的计算资源。自然地，我们好奇是否存在类似的结果对于双眼视觉是否也存在。

在本节的剩余部分，我们将开始证明双眼视觉的3D逆向投影方程。然后，3D逆向投影的结果将帮助我们证明双眼视觉的3D前向投影方程。

### 4.1. 双眼视觉中位置的3D逆向投影方程

将方程6应用到图3将产生以下两个关系：

$$
\left[\begin{array}{c}
k_{l} \cdot X \\
k_{l} \cdot Y \\
k_{l} \cdot Z \\
k_{l}
\end{array}\right]=C_{i}^{l} \cdot\left[\begin{array}{c}
u_{l} \\
v_{l} \\
1
\end{array}\right]
$$

和

$$
\left[\begin{array}{c}
k_{r} \cdot X \\
k_{r} \cdot Y \\
k_{r} \cdot Z \\
k_{r}
\end{array}\right]=C_{i}^{r} \cdot\left[\begin{array}{c}
u_{r} \\
v_{r} \\
1
\end{array}\right]
$$

其中$C_{i}^{l}=\left\{a_{ij}^{l}, i \in[1,3], j \in[1,4]\right\}$和$C_{i}^{r}=\left\{a_{ij}^{r}, i \in[1,3], j \in[1,4]\right\}$分别是左右相机的逆投影矩阵，$(u_{l}, v_{l})^{t}$是点b的索引坐标，b是点Q在左相机内的图像，$(u_{r}, v_{r})^{t}$是点a的索引坐标，a是点Q在右相机内的图像。

现在，如果我们定义矩阵$B_{i}$如下：

$$
B_{i}=\left[\begin{array}{ccccc}
a_{11}^{l} & a_{12}^{l} & a_{11}^{r} & a_{12}^{r} & a_{13}^{l}+a_{13}^{r} \\
a_{21}^{l} & a_{22}^{l} & a_{21}^{r} & a_{22}^{r} & a_{23}^{l}+a_{23}^{r} \\
a_{31}^{l} & a_{32}^{l} & a_{31}^{r} & a_{32}^{r} & a_{33}^{l}+a_{33}^{r} \\
a_{41}^{l} & a_{42}^{l} & a_{41}^{r} & a_{42}^{r} & a_{43}^{l}+a_{43}^{r}
\end{array}\right]
$$

方程17和方程18的组合（即，求和）将产生以下结果：

$$
\left[\begin{array}{c}
k \cdot X \\
k \cdot Y \\
k \cdot Z \\
k
\end{array}\right]=B_{i} \cdot\left[\begin{array}{c}
u_{l} \\
v_{l} \\
u_{r} \\
v_{r} \\
1
\end{array}\right]
$$

其中$k=k_{l}+k_{r}$。

有趣的是，方程20是双眼视觉系统的3D逆向投影方程。矩阵$B_{i}$是双眼视觉的3D逆向投影矩阵。这个矩阵是一个$4 \times 5$的矩阵，内含20个元素。由于缩放因子$k$的存在，矩阵$B_{i}$内只有19个独立元素可以通过校准过程确定。

例如，一组已知值$\left\{(X, Y, Z),\left(u_{l}, v_{l}\right),\left(u_{r}, v_{r}\right)\right\}$将从方程20中产生三个约束。因此，使用17组$\left\{(X, Y, Z),\left(u_{l}, v_{l}\right),\left(u_{r}, v_{r}\right)\right\}$的列表，矩阵$B_{i}$可以提前、即时或即时完全计算出来。

有趣的是，在仿人机器人头部安装的双眼视觉系统的背景下，仿人机器人手中的视觉观察到的指尖可以轻松提供一组已知值$\left\{(X, Y, Z),\left(u_{l}, v_{l}\right),\left(u_{r}, v_{r}\right)\right\}$。

这些值将允许仿人机器人实现即时或即时校准的场景。

### 4.2. 双眼视觉中位置的3D前向投影方程

现在，如果我们计算矩阵$B_{i}$的伪逆，方程20将变为：

$$
\left[\begin{array}{c}
s \cdot u_{l} \\
s \cdot v_{l} \\
s \cdot u_{r} \\
s \cdot v_{r} \\
s
\end{array}\right]=B_{f} \cdot\left[\begin{array}{l}
X \\
Y \\
Z \\
1
\end{array}\right]
$$

其中$s=1 / k$且$B_{f}=\left(B_{i}^{t} \cdot B_{i}\right)^{-1} \cdot B_{i}^{t}$。

方程21是双眼视觉的3D前向投影方程，其中矩阵$B_{f}$是双眼视觉的3D前向投影矩阵，如图6所示。

![图6。双眼视觉系统的3D前向和逆向投影的

完整说明](https://cdn.mathpix.com/cropped/2024_01_16_982703e8101a6fa6b936g-10.jpg?height=854&width=1160&top_left_y=898&top_left_x=445)

图6. 双眼视觉系统的3D前向和逆向投影的完整说明。

### 4.3. 双眼视觉位移的3D逆向投影方程

数学上，方程20是可微分的。此外，导数$\left(\frac{d X}{d t}, \frac{d Y}{d t}, \frac{d Z}{d t}\right)^{t}$与导数$\left(\frac{d u_{l}}{d t}, \frac{d v_{l}}{d t}, \frac{d u_{r}}{d t}, \frac{d v_{r}}{d t}\right)^{t}$之间的关系与变化$(\Delta X, \Delta Y, \Delta Z)^{t}$与变化$\left(\Delta u_{l}, \Delta v_{l}, \Delta u_{r}, \Delta v_{r}\right)^{t}$之间的关系相同。这是因为如果双眼视觉的运动链保持不变，矩阵$B_{f}$是一个常数矩阵【20】。

现在，我们去掉矩阵$B_{i}$的最后一列（注意：$B_{i}=\left\{b_{ij}, i \in[1,4], j \in[1,5]\right\}$）并使用剩余的元素定义一个新矩阵$D_{i}$如下：$D_{i}=\left\{d_{ij}=\frac{1}{k} \cdot b_{ij}, i \in[1,4], j \in[1,4]\right\}$。这样，方程20的微分将产生以下结果【20】：

$$
\left[\begin{array}{c}
\Delta X \\
\Delta Y \\
\Delta Z
\end{array}\right]=D_{i} \cdot\left[\begin{array}{c}
\Delta u_{l} \\
\Delta v_{l} \\
\Delta u_{r} \\
\Delta v_{r}
\end{array}\right]
$$

方程22代表双眼视觉系统中位移的3D逆向投影。由于比例$k$不是常数，矩阵$D_{i}$将不是一个常数矩阵。然而，在实践中，我们可以将任何实例的矩阵$D_{i}$视为一个常数矩阵。这样，方程22可以在自主机器人的感知、规划和控制的外部循环中使用，如图2所示。

因此，方程22是双眼视觉中位移的3D逆向投影的迭代解决方案。将方程22应用于机器人引导是一个优势。这是因为方程22将使得感知-规划-控制循环不对双眼视觉系统的噪声和内部参数的变化敏感。

### 4.4. 双眼视觉位移的3D前向投影方程

现在，通过对矩阵$D_{i}$进行简单的伪逆计算，方程22将允许我们得到以下双眼视觉中位移的3D前向投影方程：

$$
\left[\begin{array}{l}
\Delta u_{l} \\
\Delta v_{l} \\
\Delta u_{r} \\
\Delta v_{r}
\end{array}\right]=D_{f} \cdot\left[\begin{array}{c}
\Delta X \\
\Delta Y \\
\Delta Z
\end{array}\right]
$$

其中$D_{f}=\left(D_{i}^{t} \cdot D_{i}\right)^{-1} \cdot D_{i}^{t}$。

总之，方程22和方程23完全描述了双眼视觉系统中位移的3D前向和逆向投影。这两个解决方案本质上是迭代的，并且可以在自主机器人的感知、规划和控制的外部循环中使用，如图7所示。

特别是，方程22使得自主机器人能够实现类人的手眼协调和头眼协调，如图7所示。例如，手眼协调或头眼协调的控制任务可以定义为最小化误差向量$\left(\Delta u_{l}, \Delta v_{l}, \Delta u_{r}, \Delta v_{r}\right)^{t}$的目标。如图7所示，误差向量$\left(\Delta u_{l}, \Delta v_{l}, \Delta u_{r}, \Delta v_{r}\right)^{t}$的历史将以可以在左右图像内观察到的路径形式出现。

![图7。实现类人手眼协调和头眼协调的场景](https://cdn.mathpix.com/cropped/2024_01_16_982703e8101a6fa6b936g-11.jpg?height=674&width=1142&top_left_y=1351&top_left_x=454)

图7. 实现类人手眼协调和头眼协调的场景。

## 5. 实验结果

本文的第一个重要贡献是图6总结的结果。本文的第二个重要贡献是图7概述的结果。在本节中，我们将分享两个实验，分别验证图6和图7所示的结果。

### 5.1. 验证3D逆向投影位置方程的真实实验

这里，我们想分享一个使用低成本硬件和低分辨率双眼相机以及小尺寸棋盘格的实验。这样，我们可以欣赏方程20和图6总结的结果的有效性。

如图8所示，

实验硬件包括一个树莓派单板计算机、一个双眼视觉模块和一个棋盘格。双眼相机的图像分辨率为$480 \times 320$像素。棋盘格的尺寸为$18 \times 24 \mathrm{~cm}$，被划分为$6 \times 8$个大小为$3.0 \times 3.0 \mathrm{~cm}$的正方形。

![图8。实验硬件包括树莓派单板计算机、双眼视觉模块和棋盘格，棋盘格用作校准数据点和测试数据点的输入](https://cdn.mathpix.com/cropped/2024_01_16_982703e8101a6fa6b936g-12.jpg?height=531&width=1188&top_left_y=377&top_left_x=431)

图8. 实验硬件包括树莓派单板计算机、双眼视觉模块和棋盘格，棋盘格用作校准数据点和测试数据点的输入。

在棋盘格内，$\{A, B, C, D\}$用作确定方程20中的矩阵$B_{i}$的校准数据点，而$\left\{T_{0}, T_{1}, T_{2}, T_{3}, T_{4}\right\}$用作校准结果的测试数据点（即，测试方程20中的矩阵$B_{i}$的有效性）。

参考方程20，矩阵$B_{i}$是一个$4 \times 5$的矩阵，其中有十九个独立元素或参数。由于单个方程20将施加三个约束，因此至少需要七对$\{X, Y, Z\}$和$\left\{u_{l}, v_{l}, u_{r}, v_{r}\right\}$来完全确定矩阵$B_{i}$。

如图9所示，我们定义一个参考坐标系如下：其$Z$轴平行于地面并指向场景。其$Y$轴垂直于地面并向下指。其$X$轴指向右手边。

然后，我们将棋盘格放置在双眼视觉系统前的四个位置。这四个位置的$Z$坐标分别为$1.0 \mathrm{~m}, 1.5 \mathrm{~m}, 2.0 \mathrm{~m}$和$2.5 \mathrm{~m}$。棋盘格垂直于通过测试数据点$T_{0}$的$Z$轴。因此，校准数据点$\{A, B, C, D\}$和测试数据点$\left\{T_{0}, T_{1}, T_{2}, T_{3}, T_{4}\right\}$的$X$和$Y$坐标是事先已知的。这些$X$和$Y$坐标的值在图9内显示。

当棋盘格放置在上述四个位置之一时，将拍摄一对立体图像。校准数据点和测试数据点的索引坐标可以自动或手动确定。

通过将校准数据点的3D坐标和索引坐标结合在一起，我们得到表1，其中包含了校准双眼视觉逆向投影方程（即，方程20）所需的数据。

![图9。校准方程20中的矩阵$B_{i}$的数据集](https://cdn.mathpix.com/cropped/2024_01_16_982703e8101a6fa6b936g-12.jpg?height=614&width=1168&top_left_y=2063&top_left_x=450)

图9. 校准方程20中的矩阵$B_{i}$的数据集。

表1. 校准双眼视觉的3D坐标和索引坐标的数据点。

| 校准数据点$\{A, B, C, D\}$的坐标和其图像的索引坐标 |  |  |  |  |  |  |  |
| :---: | :---: | :---: | :---: | :---: | :---: | :---: | :---: |
|  | X_tru (cm) | Y_tru (cm) | Z_tru (cm) | ul | $\mathrm{vl}$ | ur | $\mathrm{vr}$ |
| A | 9 | -6 | 100 | 135 | 282 | 91 | 283 |
|  | 9 | -6 | 150 | 146 | 297 | 114 | 298 |
|  | 9 | -6 | 200 | 152 | 305 | 127 | 307 |
|  | 9 | -6 | 250 | 155 | 310 | 134 | 312 |
| B | -3 | -6 | 100 | 196 | 281 | 152 | 284 |
|  | -3 | -6 | 150 | 186 | 296 | 155 | 298 |
|  | -3 | -6 | 200 | 183 | 305 | 157 | 307 |
|  | -3 | -6 | 250 | 180 | 310 | 159 | 312 |
| C | 9 | 6 | 100 | 136 | 346 | 89 | 346 |
|  | 9 | 6 | 150 | 146 | 339 | 113 | 340 |
|  | 9 | 6 | 200 | 152 | 337 | 126 | 339 |
|  | 9 | 6 | 250 | 155 | 335 | 152 | 325 |
| D | -3 | 6 | 100 | 198 | 345 | 151 | 347 |
|  | -3 | 6 | 150 | 188 | 338 | 154 | 341 |
|  | -3 | 6 | 200 | 183 | 337 | 158 | 339 |
|  | -3 |

 6 | 250 | 180 | 335 | 158 | 337 |

使用表1中列出的数据，我们得到以下矩阵$B_{i}$的结果：

$$
B_{i}=\left[\begin{array}{ccccc}
-0.4251 & -0.7861 & -0.2245 & 0.8267 & 92.6220 \\
0.2167 & -0.3717 & -0.2730 & 0.9845 & -196.0451 \\
-1.5409 & 14.4961 & 1.2774 & -14.9300 & -71.2214 \\
-0.0874 & 0.1758 & 0.0873 & -0.1758 & 1.0000
\end{array}\right]
$$

现在，我们使用表1中的索引坐标、校准后的矩阵$B_{i}$和方程20来计算校准数据点$\{A, B, C, D\}$的3D坐标。将这些计算的3D坐标放入表1，我们将得到表2，帮助我们比较$\{A, B, C, D\}$的真实3D坐标值和计算的3D坐标值。

类似地，我们使用测试数据点$\left\{T_{0}, T_{1}, T_{2}, T_{3}, T_{4}\right\}$的索引坐标、校准后的矩阵$B_{i}$和方程20来计算$\left\{T_{0}, T_{1}, T_{2}, T_{3}, T_{4}\right\}$的3D坐标。然后，将$\left\{T_{0}, T_{1}, T_{2}, T_{3}, T_{4}\right\}$的真实3D坐标值和计算的3D坐标值放入表格，我们得到表3，帮助我们欣赏方程20的实用性和有效性。

表2. 校准数据点$\{A, B, C, D\}$的真实值和计算值的3D坐标的比较。

| 使用校准数据点$\{A, B, C, D\}$的真实坐标和计算坐标的比较 |  |  |  |  |  |  |  |  |  |  |
| :---: | :---: | :---: | :---: | :---: | :---: | :---: | :---: | :---: | :---: | :---: |
|  | X_tru (cm) | X_cal (cm) | Y_tru (cm) | Y_cal (cm) | Z_tru (cm) | Z_cal (cm) | ul | vl | ur | vr |
| A | 9 | 9.98 | -6 | -7.84 | 100 | 91.53 | 135 | 282 | 91 | 283 |
|  | 9 | 10.07 | -6 | -4.12 | 150 | 162.5 | 146 | 297 | 114 | 298 |
|  | 9 | 6.83 | -6 | -5.34 | 200 | 110.1 | 152 | 305 | 127 | 307 |
|  | 9 | 6.19 | -6 | -4.98 | 250 | 234.3 | 155 | 310 | 134 | 312 |
| B | -3 | -4.91 | -6 | -5.47 | 100 | 86.31 | 196 | 281 | 152 | 284 |
|  | -3 | -1.91 | -6 | -5.91 | 150 | 169.6 | 186 | 296 | 155 | 298 |
|  | -3 | -2.83 | -6 | -6.92 | 200 | 214 | 183 | 305 | 157 | 307 |
|  | -3 | -0.5 | -6 | -6.01 | 250 | 236.5 | 180 | 310 | 159 | 312 |
| C | 9 | 8.78 | 6 | 6.50 | 100 | 95.4 | 136 | 346 | 89 | 346 |
|  | 9 | 10.07 | 6 | 6.11 | 150 | 168.7 | 146 | 339 | 113 | 340 |
|  | 9 | 8.83 | 6 | 5.96 | 200 | 193.7 | 152 | 337 | 126 | 339 |
|  | 9 | 9.19 | 6 | 4.41 | 250 | 230.5 | 155 | 335 | 152 | 325 |
| D | -3 | -6.75 | 6 | 8.92 | 100 | 90.8 | 198 | 345 | 151 | 347 |
|  | -3 | -5.92 | 6 | 2.69 | 150 | 170.5 | 188 | 338 | 154 | 341 |
|  | -3 | 0.22 | 6 | 4.24 | 200 | 215.3 | 183 | 337 | 158 | 339 |
|  | -3 | -4.39 | 6 | 6.44 | 250 | 237.5 | 180 | 335 | 158 | 337 |

表3. 测试数据点$\left\{T_{0}, T_{1}, T_{2}, T_{3}, T_{4}\right\}$的真实值和计算值的3D坐标的比较。

| 使用测试数据点$\{\mathrm{T}0, \mathrm{~T}1, \mathrm{~T}2, \mathrm{~T}3, \mathrm{~T}4\}$的真实坐标和计算坐标的比较 |  |  |  |  |  |  |  |  |  |  |
| :---: | :---: | :---: | :---: | :---: | :---: | :---: | :---: | :---: | :---: | :---: |
|  | X_tru $(\mathrm{cm})$ | X_cal $(\mathrm{cm})$ | Y_tru (cm) | Y_cal (cm) | Z_tru (cm) | Z_cal $(\mathrm{cm})$ | ul | vl | ur | vr |
| то | 0 | 1.36 | 0 | 4.28 | 100 | 89.68 | 182 | 313 | 135 | 315 |
|  | 0 | 3.24 | 0 | 2.61 | 150 | 164.32 | 177 | 317 | 144 | 319 |
|  | 0 | 1.02 | 0 | -1.84 | 200 | 219.22 | 175 | 320 | 150 | 323 |
|  | 0 | 1.17 | 0 | -2.20 | 250 | 237.69 | 174 | 322 | 152 | 312 |
| T1 | -6 | -6.79 | -6 | -4.80 | 100 | 90.33 | 221 | 281 | 166 | 285 |
|  | -6 | -1.32 | -6 | -1.52 | 150 | 161.01 | 197 | 296 | 165 | 298 |
|  | -6 | -1.77 | -6 | -4.71 | 200 | 213.04 | 190 | 305 | 165 | 307 |
|  | -6 | 1.24 | -6 | -5.45 | 250 | 275.93 | 186 | 310 | 164 | 312 |
| T2 | 6 | 8.04 | -6 | -6.23 | 100 | 95.53 | 150 | 282 | 106 | 284 |
|  | 6 | 10.7 | -6 | -0.48 | 150 | 164.95 | 156 | 297 | 124 | 298 |
|  | 6 | 7.54 | -6 | -3.30 | 200 | 214.39 | 159 | 305 | 135 | 307 |
|  | 6 | 7.08 | -6 | -2.68 | 250 | 232.64 | 161 | 310 | 140 | 312 |
| T3 | -6 | -8.47 | 6 | 10.96 | 100 | 83.66 | 214 | 345 | 166 | 348 |
|  | -6 | -4.45 | 6 | 5.76 | 150 | 165.10 | 198 | 338 | 164 | 341 |
|  | -6 | -0.57 | 6 | 7.16 | 200 | 210.32 | 191 | 337 | 165 | 339 |
|  | -6 | 1.78 | 6 | 5.60 | 250 | 233.31 | 186 | 335 | 164 | 337 |
| T4 | 6 | 6.07 | 6 | 8.26 | 100 | 94.98 | 151 | 345 | 104 | 346 |
|  | 6 | 10.83 | 6 | 10.58 | 150 | 162.62 | 157 | 339 | 123 | 340 |
|  | 6 | 9.62 | 6 | 7.89 | 200 | 204.51 | 160 | 337 | 134 | 329 |
|  | 6 | 8.71 | 6 | 6.34 | 250 | 224.93 | 162 | 335 | 140 | 337 |

考虑到数字图像的低分辨率（即，$480 \times 320$像素）和小尺寸的棋盘格（即，$18 \times 24 \mathrm{~cm}$，被划分为$6 \times 8$个正方形），我们可以说表2和表3中显示的比较结果对于我们来说足够好，足以在实验中验证方程20的有效性。在实践中，更高分辨率的图像和更大尺寸的棋盘格自然会增加双眼视觉校准的准确性以及使用方程20计算的3D坐标的准确性。

### 5.2. 验证3D逆向投影位移方程的仿真

图7中显示的手眼协调的图片是一个真实的实验，它已经证明了双眼视觉中位移的3D逆向投影的有效性，如方程22所描述。这个真实演示的视频已经在新加坡的国家电视新闻中播放。这里，我们想分享一个仿真结果，在图10的情境下，头眼协调指导直升机降落在船只的可移动甲板上。

![图10。头眼协调指导直升机在船只的可移动甲板上降落的示意图](https://cdn.mathpix.com/cropped/2024_01_16_982703e8101a6fa6b936g-14.jpg?height=870&width=1282&top_left_y=1758&top_left_x=387)

图10. 头眼协调指导直升机在船只的可移动甲板上降落的示意图。

在方程22中，矩阵$D_{i}$是一个$3 \times 4$的矩阵，其中有十一个独立元素或参数。由于一对$\{\Delta X . \Delta Y, \Delta Z\}\}$和$\left\{\Delta u_{l}, \Delta v_{l}, \Delta u_{r}, \Delta v_{l}\right\}$施加三个约束，四对这样的校准数据集足以完全确定矩阵$D_{i}$。

校准后，方程22可以用作图2所示的感知和规划模块。图10场景的仿真结果显示在图11中。完整的视频可以在https://youtu.be/BCWpOJyGr6E上观看。

![图11。使用方程22作为感知和规划模块的仿真结果，在头眼协调的背景下指导直升机降落在可移动甲板上](https://cdn.mathpix.com/cropped/2024_01_16_

982703e8101a6fa6b936g-15.jpg?height=478&width=1254&top_left_y=570&top_left_x=411)

图11. 使用方程22作为感知和规划模块的仿真结果，在头眼协调的背景下指导直升机降落在可移动甲板上。

有趣的是，在安装在自主仿人机器人头部的双眼视觉系统的背景下，一对类人机器人手自动产生的五对$\{\Delta X . \Delta Y, \Delta Z\}\}$和$\left\{\Delta u_{l}, \Delta v_{l}, \Delta u_{r}, \Delta v_{l}\right\}$对应于五对指尖之间的位移。这样的观察帮助我们理解人类双眼视觉的力量和灵活性。

## 6. 结论

在本文中，我们证明了两个重要的方程，即方程20和方程22。这两个方程完全描述了类人双眼视觉系统中的3D投影。有趣的是，它们类似于单眼视觉系统中2D前向和逆向投影的方程。这些发现帮助我们将单眼视觉和双眼视觉的几何方面统一为前向和逆向投影的方程。最重要的是，方程20和方程22是两个线性方程组的形式，可以容易地由人工神经元网络实现。因此，这篇论文的理论发现帮助我们理解为什么来自人类视觉的大量视觉信号不会导致人类大脑的疲劳。此外，方程20和方程22中的矩阵可以通过校准过程轻松获得，而无需知道双眼视觉中相机的内在参数。有趣的是，如果双眼视觉系统安装在仿人机器人的头部，仿人机器人的指尖将能够轻松提供校准方程20和方程22所需的数据集。这意味着即时或即时校准不是一个难题。这一事实帮助我们理解为什么人类视觉能够适应人体的成长。我们希望看到方程20和方程22在未来的研究和产品开发中被广泛采用和应用，这些研究和产品开发与科学、工程和工业中各种目的的双眼视觉的使用相关。

作者贡献：概念化，Ming Xie；方法论，Ming Xie和Yuhui Fang；软件，Yuhui Fang和Tingfeng Lai；验证，Yuhui Fang和Tingfeng Lai；形式分析，Ming Xie；调查，Ming Xie，Yuhui Fang和Tingfeng Lai；资源，Ming Xie；数据管理，Yuhui Fang；撰写原稿准备，Ming Xie；撰写 - 审查和编辑，Ming Xie。；可视化，Ming Xie和Yuhui Fang；监督，Ming Xie；项目管理，Ming Xie；资金获取，Ming Xie。所有作者已阅读并同意发表的稿件版本。

资助：本研究由新加坡国防部未来系统和技术司提供资金支持，授权号PA9022201473"。

机构审查委员会声明：不适用"。

数据可用性声明：与本文相关的所有数据将根据请求提供。访问数据受南洋理工大学，新加坡的数据保护政策限制。

致谢：我们要感谢新加坡国防部未来系统和技术司对NTU的RobotX挑战队的财政支持。

利益冲突：不存在利益冲突。

## 参考文献

1. Xie, M. Hu, Z. C. 和 Chen, H. 《人工智能的新基础》。世界科学出版社，2021。
2. Horn, B. K. P. 《机器人视觉》。麻省理工学院出版社，1986。
3. Tolhurst, D. J. 人类视觉中的持续和瞬态通道。视觉研究，1975；第15卷，第10期，第1151-1155页。
4. Fahle M 和 Poggio T. 视觉超敏感：人类视觉中的时空插值，伦敦皇家学会会议记录，1981。
5. Enns, J. T. 和 Lleras, A. 下一个是什么？人类视觉中预测的新证据。认知科学趋势，2008；第12卷，第9期，第327-333页。
6. Laha, B., Stafford, B. K. 和 Huberman, A. D. 从眼睛到大脑的光路再生。科学，2017；第356卷，第6342期，第1031-1034页。
7. Gregory, R. 《眼睛与大脑：看见的心理学 - 第五版》，普林斯顿大学出版社，2015。
8. Pugh, A. (编辑)。《机器人视觉》。施普林格出版社，2013。
9. Samani, H. (编辑)。《认知机器人学》。CRC出版社，2015
10. Erlhagen, W. 和 Bicho, E. 认知机器人学中的动态神

经场方法。神经工程杂志，2006；第3卷，第3号。
11. Cangelosi, A. 和 Asada, M. 《认知机器人学》。麻省理工学院出版社，2022。
12. Faugeras, O. 《三维计算机视觉：几何视角》。麻省理工学院出版社，1993。
13. Paragios, N., Chen, Y. M. 和 Faugeras, O. (编辑)。《计算机视觉中的数学模型手册》。施普林格，2006。
14. Faugeras, O., Luong, Q. T. 和 Maybank, S. J. 相机自标定：理论和实验。欧洲计算机视觉会议。施普林格，1992；LNCS，第588卷。
15. Stockman, G. 和 Shapiro, L. G. 《计算机视觉》。普伦蒂斯大厅，2001。
16. Shirai, Y. 《三维计算机视觉》。施普林格，2012。
17. Khan, S., Rahmani, H., Shah, S. A. A. 和 Bennamoun, M. 《计算机视觉卷积神经网络指南》。施普林格，2018。
18. Szeliski, R. 《计算机视觉：算法与应用》。施普林格，2022。
19. Brooks, R. 机器人学的新方法。科学，1991；第253卷，第5025期。
20. Xie, M. 《机器人学基础：将感知链接到行动》。世界科学出版社，2003。
21. Siciliano, B. 和 Khatib, O. 《机器人学手册》。施普林格，2016。
22. Murphy, R. 《人工智能机器人学 - 第二版》。麻省理工学院出版社，2019。

免责声明/出版商声明：所有出版物中的声明、意见和数据仅代表个别作者/贡献者和/或编辑的观点，并不代表MDPI和/或编辑的观点。MDPI和/或编辑不承担任何因文中提到的任何想法、方法、说明或产品而对人或财产造成的任何伤害的责任。