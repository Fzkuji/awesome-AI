本来想写一个Memory of Large Foundation Model的Survey，没想到Meta力大砖飞，直接写了个完整版：

[Advances and Challenges in Foundation Agents: From Brain-Inspired Intelligence to Evolutionary, Collaborative, and Safe Systems](https://arxiv.org/abs/2504.01990)

只能先看看他们的观点，搞搞具体的研究了，可恶啊。

---

## 1. Overall Framework

首先我们看看，Meta认为为了实现AGI，模型大致需要具备哪些能力：

![](https://pic1.zhimg.com/v2-50bb6d3feebaa92c8ff0532783dbcdd2_1440w.jpg)

Figure 1.2: An overview of our general framework for describing an intelligent agent loop and agent society.

核心的三个组件其实显而易见，我个人也比较认可，那就是：

1. **感知**：获取世界的真实信息
2. **思考**：处理信息，包括思考和记忆，辅之以内在驱动和情感
3. **行动**：对观察事物的反应，包括语言、动作，甚至是图像

---

## 2. Human Memory

### 2.1 Classifications

记忆仍然属于思考的范畴，本质是对感知的思考过程中的信息进行保存。最经典的分类莫过于将记忆分为**感觉记忆**、**短期记忆**和**长期记忆：**

![](https://pic1.zhimg.com/v2-066558915ab926421e62bdc5c9ff51b4_1440w.jpg)

Figure 3.1: The hierarchical taxonomy of human memory system.

其中，长期记忆有更多的详细划分，但没有太多意义了，通常我们设计的模型不会单独给每种记忆设计相应的模块。99%的情况还是将其“混为一谈”。

### 2.2 Models of Human Memory

人们在认识到记忆的不同类别之后，开始尝试搭建一些框架，试图概括整个记忆的运行逻辑。当然，这也是为了简化前面的各种分类，即使是人脑，很多长期记忆也不是单独存在的。

**The Multi-Store (Modal) Model.** 最早的标准三阶段记忆存储结构的模型。

![](https://pic1.zhimg.com/v2-463a498d679b5eee50a75ad48ee53d36_1440w.jpg)

Figure 3.2: Atkinson-Shiffrin three-stage model of human memory.

  

**Working Memory Models.** 这类模型认为短期记忆只是存储的信息，我们需要对短期记忆进行整合、与长期记忆进行桥接，因此提出**工作记忆**这个概念。

![](https://picx.zhimg.com/v2-3bae78313525e1713336df830c509a7f_1440w.jpg)

Figure 3.3: Baddeley‘s model of working memory.

**Serial-Parallel-Independent (SPI) Model.** 即（串行-并行-独立）模型

![](https://pic3.zhimg.com/v2-600ee5593f74ce9f5caf61cf30909bea_1440w.jpg)

Figure 3.4: The Serial-Parallel Independent (SPI) model of human memory.

- **Serial（串行）**：感知信息进入系统是有顺序的，例如先通过感知系统，再进入语义或情节系统。
- **Parallel（并行）**：一旦信息被编码，它可以**同时**被不同模块（如语义、情节）使用。
- **Independent（独立）**：各个模块**在使用上可以互相独立**，不必每次都依赖其他模块来操作（例如可以有程序性记忆而没有情节记忆）。

**Global Workspace Theory (GWT) and the IDA/LIDA Framework.** 全局工作空间理论

![](https://pic3.zhimg.com/v2-bbe13d9fb4f3ed8fbf5d27d424e8ed7e_1440w.jpg)

Global Workspace Theory (GWT) and the IDA/LIDA Framework.

全局工作空间理论（Global Workspace Theory, GWT）将意识视为一种“广播机制”，认为大脑中存在多个专门处理感知和认知任务的模块，只有当某条信息被广播到全局工作空间中，才能进入意识和工作记忆，供整个系统共享与处理。

将大脑想象成一个公司，很多人在后台干活（视觉、记忆、听觉），“广播室”把某个重要的信息广播出来（比如你突然想到今晚有个会议），所有系统都能听到这个广播，并据此调整工作（比如安排出门路线、调整计划）。

**ACT-R and Cognitive Architectures.** 思想的适应性控制-理性

![](https://pica.zhimg.com/v2-7966e3719cbaf3bbe3c6ead38ce38860_1440w.jpg)

This represents an abstraction of the most important processes in the ACT-R model.

这是一种综合性的认知架构，模拟人类如何感知、记忆、思考与行动。它将大脑划分为多个功能模块，如视觉、动作、陈述性记忆和程序性记忆，各模块通过缓冲区交互，构成完整的认知流程。ACT-R 区分事实知识（chunk）与条件规则（if-then），通过符号规则驱动认知行为，同时引入数学函数进行次符号调节，以更真实地还原人类的反应速度、记忆强度和策略选择。

这个模型设计得过于复杂了，看上去非常不优雅。

---

## 3. Meta's Memory

总结了人类记忆得模式后，我们可以开始思考，要实现AGI，需要什么样的记忆。

### 3.1 Classifications

与人类记忆类似，我们仍然需要对AGI的记忆进行划分。Meta的划分：

1. **感觉记忆**（Sensory Memory）：同理感觉记忆应当为原始的数据输入，即摄像头、麦克风等各种传感器获取到的原始信息。
2. **短期记忆**（Short-Term Memory）：Meta认为短期记忆充当着连接感觉记忆和长期记忆的瞬时动态工作空间。同时短期记忆可以细分为**上下文记忆**和**工作记忆**。
	1. 上下文记忆：通过感觉记忆处理得到的基础记忆
	2. 工作记忆：对上下文记忆进行进一步操作得到的记忆
3. **长期记忆**（Long-Term Memory）：这里Meta和人类记忆一样，将长期记忆分得很细，但是很明显不同研究的实现方式不一样，Meta将这些工作杂揉了起来。
4. **显式记忆**（Explicit Memory）：可被直接提取与使用的记忆
	1. 语义记忆（Semantic Memory）：存储通用知识、事实、概念。比如，鱼含有蛋白质、刀在厨房
	2. 情节记忆（Episodic Memory）：存储特定事件、交互历史、情境路径。从厨房走到客厅再走到花园
5. **隐式记忆**（Implicit Memory）：无需显式调用即可影响行为
	1. 程序性记忆（Procedural Memory）：储存可复用的技能或执行计划；提升任务效率
	2. 启动效应（Priming）：记录状态变化与响应模式，使智能体能快速做出合适反应

总结来说，Meta仍然是按照人类记忆的模型来划分目前的研究的，这也导致同一个类别的记忆的实现方式可能完全不同。比如隐式记忆，Meta举例说Cradle/Jarvis-1是程序性记忆，但是这些工作是较早期的，仍然用文本形式保存记忆，很难将他们归于隐式记忆。

### 3.2 The Memory Lifecycle

下面是Meta整理的，不同工作设计的记忆类型和完整的生命周期流程，记忆在生命周期内，包括了获取、编码、推导、索引和使用：

![](https://pica.zhimg.com/v2-9c05403e4e7f3e1dee9db7c2cb1bb012_1440w.jpg)

Figure 3.7: Illustration of the memory lifecycle.

![](https://pic3.zhimg.com/v2-8f81c27f974bba4126b1ce8a545dccfa_1440w.jpg)

Table 3.1: Summary of the memory module in various agents. Refer to Figure 3.6 for abbreviations.

#### 3.2.1 Memory Acquisition

由于感觉记忆的信息量太大，因此记忆获取涉及两个关键的机制：信息压缩（information compression）和经验巩固（experience consolidation）。

1. **信息压缩**：初始的信息压缩采取较基础的、损失性的降维方法，旨在快速过滤掉不相关或冗余数据。例如：

- 对于图像，可能使用下采样方法；
- 对文本数据，基于简单的启发式规则提取关键短语或片段；
- 对音频数据，识别音频数据中的显著变化部分来降低数据量。

一些具体案例包括：

- LMAgent通过提示LLM（大语言模型）主动压缩信息以提供高效率的感官记忆；
- ReadAgent通过将文本分为多个页面（episode pagination）实现压缩；
- GraphRead则提出以图结构的方法压缩长文本，兼顾信息保留和效率。

2. **经验巩固**：在获得信息的初期，根据已有的经验或偏好优先处理最可能重要的数据。例如：

- 如智能体拥有对运动对象的偏好，则优先选取包含运动内容的视觉数据；
- 一些智能体系统利用语境相关性和回忆频率等指标，动态更新长时记忆；
- Expel智能体利用经验池（Experience Pool）储存从训练任务中提取的知识，帮助跨越至未见任务的泛化；
- MindOS设计以工作记忆为核心的中央处理模块，将任务相关经验巩固转化为结构化的思想，从而辅助未来决策和行动。

个人感觉大部分工作只是将自身工作的设计套用了记忆的形式，并不是从根本上去设计一个AGI的模型。

#### 3.2.2 Memory Encoding

记忆编码是对经过初步过滤后的感知信息进行转化，使之成为易于存储且未来能有效利用的内在表示。

这一过程中的核心环节是选择性过滤 (selective filtering)，这类似于人类认知过程中的选择性注意能力。编码任务的主要挑战来自于原始感知数据信息的复杂性、高维度性以及干扰性噪声。为有效应对此类挑战，现代方法通常采用两种关键机制：选择性注意 (Selective Attention) 和多模态信息融合 (Multi-modal Fusion)。

**选择性注意**：模仿人类认知，动态地将计算资源集中于输入信息中最具相关性或最重要的部分，例如：
- 图像中的特定区域；
- 文本当中的关键词；
- 音频信号中的特定频率范围。
现实应用中的案例包括：
- MS智能体使用基于LLM评分器的选择机制，仅保留记忆内容中分数最高的一半，从而有效压缩共享记忆；
- GraphVideoAgent利用基于图结构的记忆进行选择性且多轮的视频场景理解，以提高问答任务的性能；
- 某些机器人控制系统则通过选择性注意过滤，专门提取桌面上与任务直接相关的物体特征。

**多模态融合**：用于整合不同来源的感知信息，如视觉与听觉数据的结合，以更深入全面地理解场景。这一融合通常发生在统一的特征表示空间中，通过跨模态编码器和对比学习（contrastive learning）等技术实现。例如：
- JARVIS-1使用视频-语言模型CLIP，将任务、计划与视觉观察等元素进行对齐，构建多模态键值记忆，以更好地存储成功经验的信息；
- Optimus-1则利用特定游戏领域（例如Minecraft）的MineCLIP模型，结合视频内容与文字指令进一步优化编码器，通过抽象的记忆池提升跨模态信息检索与推理能力。该方法还能作为额外反馈过滤处理信息，一致化数据表示。
- Qwen2.5-Omni中的TMRoPE的方案是用时间对齐的位置嵌入算法，将音频和视频帧按2秒分块，交替排序，通过三维RoPE（高度、宽度、时间）对齐模态间时序。
- Llama 4刚刚发布，使用了early fusion原生多模态？？具体实现有待研究。

这里值得思考的是，感觉记忆是通过传感器获得的原始信息，而大语言模型输入的文本是计算机编码后的文字，本质是将视觉图像的文字进行了编码。前者是时序的，而后者似乎是恒定的。如何将这两类信息进行融合似乎还需要进一步研究，现有工作基本将其统一转换为token，拼接到一起输入注意力模型。

#### 3.2.3 Memory Derivation

_下面都是GPT生成的，因为感觉没啥意思，属于论文大杂烩_

记忆推导通常包括以下几种策略：反思（Reflection）、内容摘要（Summarization）、知识蒸馏（Knowledge Distillation）和选择性遗忘（Selective Forgetting）。

**反思**（Reflection）：指智能体主动对已有记忆进行分析，挖掘模式、逻辑关系与潜在矛盾点。这一过程可被突发事件（如意外的结果）触发，也可定期在后台进行。具体包括记忆对比、因果推理及假设构建。例如：
- ExpeL利用反思收集过去经验，以支持对未见任务的泛化及在失败后的反复尝试。
- R2D2则将记忆视作回放缓冲区（replay buffer），利用反思机制修正失败执行轨迹，再结合成功轨迹构建更为完善的反思记忆，为决策提供参考。

**内容摘要**（Summarization）：旨在生成精炼的信息表示，同时保留最核心内容，例如从长文档中抽取关键句子、生成摘要对话信息等。方法可以是从简单的抽取式摘要到先进的基于大语言模型（LLMs）的生成式摘要。例如：
- 部分研究提出递归总结历史对话，支持长期对话记忆推导；
- Healthcare Copilot则通过对医学对话进行重点摘要，仅记住和患者医疗历史高度相关的重要信息。

**知识蒸馏**（Knowledge Distillation）：用于将大型复杂的模型或多个专业模型的知识迁移至小型、高效的模型中。此策略常被应用于资源受限的智能体之中，用以提高泛化能力。例如：
- AoTD从任务子步骤执行轨迹提取文本式思考链，将其蒸馏到视频大语言模型（Video-LLM）中，有效提升视频问答任务的性能；
- LDPD从专家智能体将决策知识迁移给学生智能体，优化学生智能体决策策略；
- MAGDi在多智能体系统中，将多个大型模型之间复杂的推理互动转化为图结构，从而蒸馏给小模型，提升低资源模型的推理能力。

**选择性遗忘**（Selective Forgetting）：从记忆中主动移除或降低使用无关、冗余或过时的信息，以防止认知超载和提升记忆效率。遗忘机制可能基于：
- 时间因素（例如旧记忆更易遗忘）；
- 使用频率（低频访问记忆更易遗忘）；
- 与当前任务的相关性（不相关的内容将被剔除）；

具体的案例包括:
- MemoryBank采用著名的艾宾浩斯遗忘曲线（Ebbinghaus Forgetting Curve），量化记忆衰减速度；
- Lyfe Agent采用层次化的总结-遗忘策略，首先聚类相关记忆内容，再优化为简洁摘要，最后删除与新记忆高度重复的旧记忆，适用于实时社会互动场景。

#### 3.2.4 Memory Retrieval and Matching

记忆检索模拟了人类在面临问题时唤起相关知识和经验的能力，实现这一目标面临多个挑战。

比较关键的比如：

- 记忆形式多样，如何从长短期记忆中获得真正对当前情境有用的信息
- 记忆信息量
- 减少干扰

Meta认为一个全面的方案可以通过以下四个关键要素来解决这些困难：

1. **构建统一的记忆表示和索引方案**  
    这一步旨在消除不同记忆类型之间的表示鸿沟，将它们嵌入到一个共同的向量空间中。可利用预训练语言模型如BERT或Sentence-BERT将基于文本的记忆转化为语义向量，同时图神经网络 (GNNs) 可以学习知识图等结构化记忆的向量表示，捕捉节点和边的关系。为了实现高效的检索，可构建多层混合索引结构，结合倒排索引进行关键词匹配，使用Faiss或Annoy等向量索引进行相似性搜索，并利用图索引进行结构化查询。
2. **上下文感知的语义相似度计算**  
    系统需开发能够理解和利用当前上下文（如智能体的状态、目标和观测）的语义相似度计算方法，支持超越关键词重叠的深度语义匹配。这包含将上下文信息编码为向量表示，并与记忆向量有效融合。在此过程中，注意力机制起到关键作用，动态计算上下文与记忆向量之间的关联，根据其相关性赋予不同权重。
3. **将记忆检索与智能体的任务执行相结合**  
    智能体需采用任务导向的顺序决策与动态路由机制，利用任务的结构化信息指导记忆检索与运用，从而支持复杂任务的分解、规划与动态调整。通过构建任务依赖图，智能体可以根据拓扑排序确定子任务的执行顺序。（这条很像Meta为了Agent硬凑的）
4. **健全的记忆管理机制**  
    记忆管理应包含遗忘和更新策略，模拟人体遗忘机制。（又绕到前面的Derivation去了）

其实匹配要么是模型参数激活，要么是注意力机制/Hidden States，要么是RAG的向量相似度匹配。

似乎也没有其他的方案了。

#### 3.2.5 Neural Memory Networks

_然后Meta开始介绍基于神经网络的记忆，整体介绍似乎比较凌乱_

首先提及了一些早期工作：Hopfield networks、 Bidirectional Associative Memories、, Neural Turing Machines (NTMs)、Memory-Augmented Neural Network (MANNs)。总结为受到大脑神经元互联性启发的联想记忆类型。具体也没细说。

然后终于提到了一个非常核心的问题：**目前大模型时代，记忆应该保存在参数中，还是保存在缓存中？**

- 如果保存在参数中，那其实我们只需要不断continual learning就可以解决问题
- 如果保存在缓存中，我们还需要考虑缓存的保存形式、更新迭代、提炼等问题，这边也提及了一些工作：SELF-PARAM、MemoryLLM、M+ model、MemoRAG、R3Mem。最后提了一嘴类似于Meta Learning的Titans。

#### 3.2.6 Memory Utilization

_再次吐槽，不是很懂为什么拆成这几个零散的部分来讲Memory，明明Retrieval和Utilization是一个事情_

其实还是按照记忆的存储格式进行划分：

- 如果是明文存储，就使用Retrieval-augmented generation (RAG)
- 如果保存在缓存中，就是Transformer-XL、 recurrent memory transformer (RMT)等等，包括一些long-context压缩的工作，比如in-context autoencoder (ICAE)、LLMLingua、Gist、CompAct。

最后又提了一下hallucination mitigation，由于我认为幻觉问题就不是问题，就不整理了（也没几篇

### 3.3 Summary and Discussion

最后做一个小的总结吧，虽然Meta列的内容很详细，但是可以看出这部分的作者没有深入思考这个问题，对于核心的问题只是浮于表面，可能是为了迎合论文的标题，没有对AGI的记忆提出建设性的意见。

其实对于AGI而言，核心的问题就是两个：

- 记忆的处理：是否需要压缩？是否需要拟合真实世界？
- 记忆的保存：保存形式如何？是否需要丢弃？

至于，如果有了记忆，怎么使用，其实现有的方案我觉得已经很能打了（注意力、RNN、RAG等等）

---

## 4. AGI Memory

虽然Meta写了整个Survey，但是无论他们是为了藏还是根本没想，记忆这个部分还是很不合格的。虽然自己再写一篇可能机会不大，但是还是把一些思考记录下来，尤其是架构上目前的变革

_以下内容包含我自己的理解，并不是Meta说的，大家自行判断_

### 3.1 Classifications

不同于Meta详尽的分类，我更倾向于从设计一个完整、可实现的记忆框架为目标，对记忆进行划分。这里记得有一个

1. **感觉记忆**（Sensory Memory）：同理感觉记忆应当为原始的数据输入，即摄像头、麦克风等各种传感器获取到的原始信息。  
    我认为，这部分记忆最重要的就是保证原始输入，即保存传感器得到的最基础的信息，不加任何修饰
2. **工作记忆**（Working Memory）：模型在处理过程中得到的记忆，比如Transformers的KV Cache，抑或是Linear Attention的Hidden States。  
    这里开始存在尚未定论的问题，比如，我们需要保存多少工作记忆？工作记忆是否需要能够恢复感觉记忆？
3. **长期记忆**（Long-Term Memory）：长期保存在模型中的记忆，平时不会显现，但是在需要回忆的时候，能够“回想”起来。  
    这部分同样存在疑惑，如果我们有无限的工作记忆，那么我们的模型参数需要保存什么？如果我们的工作记忆有限，如何让模型参数保存更多的信息？

我想直接从这三个部分来分析。

### 3.2 Sensory Memory

感觉记忆目前在大模型中似乎是缺失的，即使是大模型内部思考，也还是明文思考，直接print出来，不知道大模型会不会不好意思。

大语言模型的问题尤为严重，因为编码后的文本是现实中不存在的事物，因此多模态模型不仅要考虑到将图片和问题统一到一个特征空间，还需要考虑他们本身不是一个维度的事物。

因此文本是否作为Sensory Memory还有待商榷。目前多模态模型的设计也非常反直觉，文本和图像同时转化为token，拼接成统一的序列。而不是像人类一样，可以连续输入视频信息，因此我仍然不相信现有的多模态模型是最终解决方案。

感觉记忆似乎更像是模型的输入，而非一个中间产物。

### 3.3 Working Memory

工作记忆其实有太多可以分析的。这里就主要分析三个关键的问题：

- 工作记忆的载体是什么？
- 工作记忆是否可以是无限的？
- 工作记忆是否需要能够恢复成感觉记忆？

**工作记忆的载体是什么？**

工作记忆目前最常见的就是Hidden States了，不管是Transformer还是Linear Transformers，还是最初的LSTM系列，这些模型都维护一个特定结构的隐层状态。

**工作记忆是否可以是无限的？**

Transformer的kv cache原则上可以无限长，而其他循环神经网络都是固定大小的状态。

考虑到人脑可以容纳的信息量，以及目前开源模型的性能，我对固定大小的工作记忆仍然存在疑虑，虽然有相当多的工作宣称他们模型的性能超过了Transformer，但是长上下文问题的解决似乎没有受到广泛的认可。

但是循环神经网络的优点在于，其可以不断更新/编辑现有的工作记忆，这似乎比Transformer的cache要灵活的多。并且支持更多形式的记忆处理。

**工作记忆是否需要能够恢复成感觉记忆？**

承接上面的问题，Transformer的cache和Mamba的hidden state目前都是计算过程的中间产物，现有的模型结构没有对其有额外的要求。

而TTT系列模型似乎对工作记忆有更高的要求，将模型的工作记忆设计为可训练的参数。但个人认为，TTT的训练只是为了让循环神经网络的hidden state更高效，在过滤所需记忆的时候精度更高，没有改变本质的运行逻辑。如果只是目前的结构，我宁愿选择超长上下文的Transformer。

值得一提的是，RWKV的作者认为：

> RWKV-7 是精确的构造，来自于第一性原理：模型的内部世界必须持续拟合外部世界。

[PENG Bo：RWKV-7 as a meta-in-context learner：从第一性原理真正理解220 赞同 · 10 评论文章](https://zhuanlan.zhihu.com/p/9397296254)

不过显然他只是为了宣传自己的RWKV-7，TTT的参数记忆感觉和拟合外部世界没什么关系。但是这个问题本身还是值得讨论的，那就是，我们的记忆是否需要能够恢复原始信息？比如完整恢复感觉记忆？

这个问题可能在大语言模型中没有太多的讨论，因为通过cache恢复当前token的文本实在是太过容易了，而且这些文本也很容易存储，并不需要专门的压缩。但当扩展到多模态大模型时，这个问题似乎逐渐重要起来。

### 3.4 Long-Term Memory

模型参数作为长期记忆的存储介质似乎是没有任何争议的。

但是kv cache是否需要作为长期记忆，作为参数的辅助，似乎也是可以考虑的。

这里的问题在于，我们需要多少容量的kv cache？虽然在编程领域，几万几十万的token数量似乎并不算什么，但是这些内容究竟是否重要，仍然是有待考量的，我们动辄将几万的代码输入大模型，虽然这已经超过了人类的水平，但似乎人并不需要那么多的信息量，就可以解决现有的问题。同时，这些kv cache似乎也并不适合作为训练的一部分。

---

## 5. Summary and Discussion

写到这似乎问题越来越多，已经完全超出我的知识水平了。

我想真正能够实现AGI的模型架构还没有到来，但已经呼之欲出。
