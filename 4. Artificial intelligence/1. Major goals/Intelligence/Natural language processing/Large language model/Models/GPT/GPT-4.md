# GPT-4

[GPT-4 Architecture, Infrastructure, Training Dataset, Costs, Vision, MoE](../../+Papers/GPT-4%20Architecture,%20Infrastructure,%20Training%20Dataset,%20Costs,%20Vision,%20MoE.pdf)
- [解读翻译](https://mp.weixin.qq.com/s/kOIoLc9nZDuM-bpNfHvW-A)

总之就是很强。

值得注意的点：

- OpenAI发现他们可以很精准地预测他们地模型效果怎么样。通常我们会先设计一个小模型，判断效果，如果可以的话再训练一个大模型。但是目前大语言模型太大了，而且很多时候小模型的效果在大模型上无法复现，大模型的涌现特征在小模型上也观测不到，因此十分困难。但是OpenAI竟然解决了这个问题。
- OpenAI发现RLHF并不能让模型的性能提高，模型的能力基本上都来源于大模型、大数据的预训练。但是RLHF能够让模型知道我们到底想要得到什么样的答案。
- GPT模型在英语文学课的考试中得分较低，因为它说的都是空话大话，这对于专业的英语老师来说还是太菜了。这可能也需要未来增加RLHF和GPT的智能水平来解决。
- 虽然GPT-4没有专门去训练其他语言，但是仍然可以解决其它语言的任务。并且在其它语言上的性能似乎和训练数据的多少没有太大关系，即使是很小众的语言也可以得到很高的性能，而使用很多的阿拉伯语反而分数很低。他们分析似乎是很语言本身有关系，比如小众语言可能和英语很类似，而阿拉伯语和英语差别很大。中文的得分很高，老师分析，大概是也使用了很多中文语料去训练才有这么高的分数。
- GPT-4也可以用prompt去模拟不同人的语气了，比如模仿家庭教师教孩子数学题，可以设置为苏格拉底式的循循善诱，这样GPT-4就不会直接告诉孩子答案，而是引导孩子自己计算结果。

局限性：

- 还是会瞎编乱造
- 有偏见
- 缺少新知识
- 逻辑不行
- 容易被骗
- 即使错了还是很自信，这个问题在使用RLHF微调之前会出现，因为此时预训练的模型已经见过了无数内容，因此GPT会很自然地对自己的回答充满自信。而在RLHF微调之后，这样的自信就会被收敛，大概就是融入人类社会了吧。因此也衍生出了一个研究问题，那就是使用RLHF到底是不是一个正确的选择。 ^5507ad




