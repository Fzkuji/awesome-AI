RLHF，即Reinforcement learning from human feedback（基于人类反馈的强化学习）

# 最新RLHF拯救语言模型「胡说八道」！微调效果比ChatGPT更好，两名华人共同一作