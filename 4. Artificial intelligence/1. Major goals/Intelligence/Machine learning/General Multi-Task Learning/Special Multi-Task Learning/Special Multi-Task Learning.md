## 1. Informal problem definiton

The special multi-task learning problem: Learn all of the tasks more quickly or more proficiently than learning them independently.
ç‹­ä¹‰å¤šä»»åŠ¡å­¦ä¹ é—®é¢˜å°±æ˜¯æ¯”ç‹¬ç«‹å­¦ä¹ **æ›´å¿«**æˆ–**æ›´ç†Ÿç»ƒ**åœ°å­¦ä¹ æ‰€æœ‰ä»»åŠ¡ã€‚

**ç›®å‰æ¥çœ‹ï¼Œä¸»è¦çš„ç›®æ ‡æ˜¯å°½é‡å‡å°‘å‚æ•°ï¼ŒåŒæ—¶è¿˜èƒ½æå‡æ€§èƒ½ã€‚**
## 2. Doesnâ€™t multi-task learning reduce to single-task learning?

Q: å¤šä»»åŠ¡å­¦ä¹ æ˜¯å¦å¯ä»¥åŒ–ç®€ä¸ºå•ä»»åŠ¡å­¦ä¹ ï¼Ÿæ¯”å¦‚ç›´æ¥æŠŠæŸå¤±å‡½æ•°åŠ èµ·æ¥è®­ç»ƒï¼Ÿ
$$\mathcal{D}=\bigcup \mathcal{D}_{i} \quad \mathcal{L}=\sum \mathcal{L}_{i}$$
A: Yes, it can! It is one approach to multi-task learning. But, we can often do better! Exploit the fact that we know that data is coming from different tasks.

## 3. Formal problem statement

### 3.1 Task notation
A task is a data generating distribution $\mathscr{T}_{i} \triangleq\left\{p_{i}(\mathbf{x}), p_{i}(\mathbf{y} \mid \mathbf{x}), \mathscr{L}_{i}\right\}$ with corresponding datasets $\mathscr{D}_{i}^{t r}$ and $\mathscr{D}_{i}^{\text {test }}$.
ä¸€ä¸ªä»»åŠ¡æ˜¯**ä¸€ä¸ªæ•°æ®åˆ†å¸ƒ**$p_{i}(\mathbf{x})$ã€**ä¸€ä¸ªç»™å®šæ•°æ®ç”Ÿæˆç»“æœçš„åˆ†å¸ƒ**$p_{i}(\mathbf{y} \mid \mathbf{x})$å’Œ**æŸå¤±å‡½æ•°**$\mathscr{L}_{i}$çš„æ€»å’Œã€‚

### 3.2 Examples of multi-task
Multi-task classification: $\mathscr{L}_{i}$ same across all tasks
å¤šä»»åŠ¡åˆ†ç±»çš„**æŸå¤±å‡½æ•°**éƒ½æ˜¯ä¸€æ ·çš„
e.g. per-language handwriting recognition, personalized spam filter

Multi-label learning: $\mathscr{L}_{i}, p_{i}(\mathbf{x})$ same across all tasks
å¤šæ ‡ç­¾å­¦ä¹ çš„**æŸå¤±å‡½æ•°**å’Œ**æ•°æ®åˆ†å¸ƒ**æ˜¯ä¸€æ ·çš„
e.g. CelebA attribute recognition, scene understanding

Q: *When might $\mathscr{L}_{i}$ vary across tasks?*
A: 
- mixed discrete, continuous labels across tasks
- multiple metrics that you care about

For MTL, we have $\enclose{horizontalstrike}{p_{\theta}(\mathbf{y} \mid \mathbf{x})} \to f_{\theta}\left(\mathbf{y} \mid \mathbf{x}, \mathbf{z}_{i}\right)$. 
$\mathbf{z}_{i}$ is the task descriptor (e.g. one-hot encoding of the task index or whatever meta-data you have).
 - personalization: user features/attributes
 - language description of the task
 - formal specifications of the task
$\mathbf{z}_{i}$æœ€ç®€å•çš„ä¾‹å­å°±æ˜¯å‘Šè¯‰æ¨¡å‹è¿™æ˜¯ç¬¬å‡ ä¸ªä»»åŠ¡ã€‚

**Vanilla MTL**
æœ€æç«¯çš„æƒ…å†µï¼ŒæŠŠæ‰€æœ‰ä»»åŠ¡çš„æŸå¤±åŠ èµ·æ¥å°±æ˜¯å¤šä»»åŠ¡çš„ç›®æ ‡ã€‚
Objective: $\min _{\theta} \sum_{i=1}^{T} \mathscr{L}_{i}\left(\theta, \mathscr{D}_{i}\right)$

## 4 Model: conditioning on the task

**å¤šä»»åŠ¡å­¦ä¹ æ¨¡å‹çš„å…³é”®é—®é¢˜ï¼š**
How should the model be conditioned on $\mathbf{z}_{i}$?
å¯¹äºä¸åŒçš„ä»»åŠ¡ï¼Œæˆ‘ä»¬å¦‚ä½•æ§åˆ¶Task descriptor $\mathbf{z}_{i}$ï¼Ÿ

What parameters of the model should be shared?
ä¸åŒä»»åŠ¡ä¹‹é—´åº”è¯¥å…±äº«ä»€ä¹ˆï¼Ÿ

### 4.1 Assumption
$\mathbf{z}_{i}$ is the one-hot task index.
å‡è®¾ï¼šTask descriptor $\mathbf{z}_{i}$åªæ˜¯one-hotå‘é‡ç´¢å¼•

### 4.2 Question
How should you condition on the task in order to share as little as possible?
é—®é¢˜ï¼šå¦‚ä½•è®¾å®šä»»åŠ¡æ¡ä»¶æ¥è®©ä»–ä»¬å…±äº«çš„ä¿¡æ¯æœ€å°‘ï¼Ÿ

### 4.3 General Answer
ä¸¤ä¸ªæç«¯ï¼š
 - independent training within a single network with no shared parameters
	ä¸€ä¸ªæç«¯æ˜¯æœ‰å¤šå°‘ä»»åŠ¡è®­ç»ƒå¤šå°‘ç½‘ç»œï¼Œå³æœ‰$n$ä¸ªä»»åŠ¡å°±è®­ç»ƒ$n$ä¸ªç½‘ç»œï¼Œæœ€ç»ˆTask descriptor $\mathbf{z}_{i}$ one-hoté€‰ä¸­å“ªä¸ªå°±ç”¨å“ªä¸ª
 - all parameters are shared
	å¦ä¸€ä¸ªæç«¯æ˜¯æ‰€æœ‰ä»»åŠ¡éƒ½ç”¨ä¸€ä¸ªæ¨¡å‹ã€‚
	ä¸ªäººè®¤ä¸ºPPTä¸Šå†™çš„æ€ªæ€ªçš„ï¼ŒæŠŠ$\mathbf{z}_{i}$ä»ä¸­é—´åŠ å…¥è¿›ç½‘ç»œï¼Œä½†æ˜¯æœ¬è´¨ä¸Šä¼¼ä¹è¿˜æ˜¯ç¬¬ä¸€ç§ã€‚ç¬¬äºŒç§æ–¹æ³•æœ€æç«¯åº”è¯¥æ˜¯ç›´æ¥æ²¡æœ‰$\mathbf{z}_{i}$ï¼Œæ¨¡å‹ç›´æ¥è¾“å‡ºå°±ç›´æ¥ç”¨ã€‚

æŠ˜ä¸­æ–¹æ¡ˆï¼š
 - Split $Î¸$ into shared parameters $Î¸^sh$ and task-specific parameters $Î¸^i$
	ä¸€éƒ¨åˆ†å‚æ•°å…±äº«ï¼Œä¸€éƒ¨åˆ†å‚æ•°ç‹¬äº«ã€‚
	ä¼˜åŒ–ç›®æ ‡ä¸ºï¼š
	$$\min _{\theta^{s h}, \theta^{1}, \ldots, \theta^{T}} \sum_{i=1}^{T} \mathscr{L}_{i}\left(\left\{\theta^{s h}, \theta^{i}\right\}, \mathscr{D}_{i}\right)$$
*å› æ­¤ï¼Œ$\mathbf{z}_{i}$ä¹Ÿå°±å†³å®šäº†æ¨¡å‹å…±äº«ä»€ä¹ˆ**å‚æ•°**ã€‚ï¼ˆFinnè¯´çš„ï¼Œæˆ‘å…¶å®ä¸å¤ªç¡®å®šï¼‰*

### 4.4 Examples
#### Concatenation-based conditioning
![500](../../../../../../Attachments/4.%20Artificial%20intelligence/1.%20Major%20goals/Intelligence/Machine%20learning/General%20Multi-Task%20Learning/Special%20Multi-Task%20Learning/Concatenation-based%20conditioning.png)
å…ˆå°†è¾“å…¥å’Œæ¡ä»¶è¿èµ·æ¥ï¼Œç„¶åè¾“å…¥åˆ°æ¨¡å‹ä¸­è¿›è¡Œè®­ç»ƒï¼Œæœ€åå¾—å‡ºç»“æœã€‚

#### Additive conditioning
![500](../../../../../../Attachments/4.%20Artificial%20intelligence/1.%20Major%20goals/Intelligence/Machine%20learning/General%20Multi-Task%20Learning/Special%20Multi-Task%20Learning/Additive%20conditioning.png)
å°†æ¡ä»¶è¾“å…¥ä¸€ä¸ªæ¨¡å‹å¾—åˆ°**æ¡ä»¶è¡¨ç¤º**ï¼Œæœ€åå°†è¾“å…¥å’Œæ¡ä»¶è¡¨ç¤º**ç›¸åŠ **ä½œä¸ºæœ€ç»ˆç»“æœã€‚

**äº‹å®å°±æ˜¯å‰é¢è¿™ä¸¤ç§æ–¹æ³•å…¶å®æœ¬è´¨ä¸Šæ˜¯ä¸€æ ·çš„ã€‚ï¼ˆä¸è¿‡ä¸ªäººè®¤ä¸ºè®­ç»ƒçš„æ—¶å€™å¯èƒ½ä¼šæœ‰ä¸åŒçš„ç»“æœï¼Œæˆ–è€…æ›´å¥½è®­ç»ƒï¼‰**

#### Multi-head architecture
![300](../../../../../../Attachments/4.%20Artificial%20intelligence/1.%20Major%20goals/Intelligence/Machine%20learning/General%20Multi-Task%20Learning/Special%20Multi-Task%20Learning/Multi-head%20architecture.png)
å¤šå¤´è¾“å…¥ï¼Œæµ…æ˜¾æ˜“æ‡‚

#### Multiplicative conditioning
![500](../../../../../../Attachments/4.%20Artificial%20intelligence/1.%20Major%20goals/Intelligence/Machine%20learning/General%20Multi-Task%20Learning/Special%20Multi-Task%20Learning/Multiplicative%20conditioning.png)
è¿™ä¸ªæ˜¯æ¡ä»¶è¡¨ç¤ºå’Œè¾“å…¥**ç›¸ä¹˜**

#### More Complex Choices
![More Complex Choices](../../../../../../Attachments/4.%20Artificial%20intelligence/1.%20Major%20goals/Intelligence/Machine%20learning/General%20Multi-Task%20Learning/Special%20Multi-Task%20Learning/More%20Complex%20Choices.png)
### 4.5 Shortcomings
- problem dependent
	ä¾èµ–äºä»»åŠ¡
- largely guided by intuition or knowledge of the problem
	åŸºäºç›´è§‰
- currently more of an art than a science
	æ›´åƒæ˜¯è‰ºæœ¯è€Œä¸æ˜¯ç§‘å­¦

## 5. Objective/Loss
*How should the objective be formed?*

### 5.1 Vanilla MTL Objective

$\min _{\theta} \sum_{i=1}^{T} \mathscr{L}_{i}\left(\theta, \mathscr{D}_{i}\right)$
æ¯ä¸ªä»»åŠ¡Lossç›¸åŠ 
### 5.2 Weight tasks differently

$\min _{\theta} \sum_{i=1}^{T} w_{i} \mathscr{L}_{i}\left(\theta, \mathscr{D}_{i}\right)$
æ¯ä¸ªä»»åŠ¡LossåŠ æƒé‡ç›¸åŠ 

æƒé‡é€‰æ‹©ï¼š
 - dynamically adjust throughout training
	e.g. 
	 - various heuristics - encourage gradients to have similar magnitudes (Chen et al. GradNorm. ICML 2018)
	 - optimize for the worst-case task loss $\min _{\theta} \max _{i} \mathscr{L}_{i}\left(\theta, \mathscr{D}_{i}\right)$ (e.g. for task robustness, or for fairness)
 - manually based on importance or priority

## 6. Optimization
*How should the objective be optimized?*

å¯¹äºVanilla MTL Objectiveï¼š$\min _{\theta} \sum_{i=1}^{T} \mathscr{L}_{i}\left(\theta, \mathscr{D}_{i}\right)$
Basic Versionï¼š
1. Sample mini-batch of tasks $â„¬ âˆ¼ \{ğ’¯_i\}$
2. Sample mini-batch datapoints for each task $\mathscr{D}_{i}^{b} \sim \mathscr{D}_{i}$
3. Compute loss on the mini-batch $\hat{\mathscr{L}}(\theta, \mathscr{B})=\sum_{\mathscr{T}_{t} \in \mathscr{B}} \mathscr{L}_{k}\left(\theta, \mathscr{D}_{k}^{b}\right)$
4. Backpropagate loss to compute gradient $\nabla_{\theta} \hat{\mathscr{L}}$
5. Apply gradient with your favorite neural net optimizer (e.g. Adam)
æ¯æ¬¡å–ä¸€ä¸ªä»»åŠ¡ï¼Œå†ä»è¯¥ä»»åŠ¡ä¸­å–ä¸€äº›æ•°æ®è®­ç»ƒæ¨¡å‹

**Note:** This ensures that tasks are sampled uniformly, regardless of data quantities.
è¿™ç¡®ä¿äº†ä»»åŠ¡è¢«ç»Ÿä¸€é‡‡æ ·ï¼Œè€Œä¸ç®¡æ•°æ®é‡å¦‚ä½•

**Tip:** For regression problems, make sure your task labels are on the same scale!
å¯¹äºå›å½’é—®é¢˜ï¼Œè¯·ç¡®ä¿æ‚¨çš„ä»»åŠ¡æ ‡ç­¾åœ¨åŒä¸€å°ºåº¦ä¸Šï¼

## 7. Challenges

### 7.1 Negative transfer

**Negative transfer:** Sometimes independent networks work the best.

Why? 
- optimization challenges
	- caused by cross-task interference
	- tasks may learn at different rates
- limited representational capacity
	- multi-task networks often need to be much larger than their single-task counterparts

Solutions
If you have negative transfer, **share less** across tasks.
å¯ä»¥å…±äº«æ›´å°‘çš„å‚æ•°

Itâ€™s not just a binary decision!
$\min _{\theta^{s h}, \theta^{1}, \ldots, \theta^{T}} \sum_{i=1}^{T} \mathscr{L}_{i}\left(\left\{\theta^{s h}, \theta^{i}\right\}, \mathscr{D}_{i}\right)+\sum_{t^{\prime}=1}^{T}\left\|\theta^{i}-\theta^{i^{\prime}}\right\|$
å¯ä»¥ä¸å…±äº«å‚æ•°ï¼Œä½†æ˜¯å¢åŠ ä¸åŒä»»åŠ¡å‚æ•°åŒºåˆ«çš„æŸå¤±$\sum_{t^{\prime}=1}^{T}\left\|\theta^{i}-\theta^{i^{\prime}}\right\|$ï¼Œè®©å¤šä¸ªä»»åŠ¡çš„æ¨¡å‹å‚æ•°å°½é‡ä¸€è‡´
âœ”ï¸ allows for more fluid degrees of parameter sharing
âŒ yet another set of design decisions / hyperparameters

### 7.2 Overfitting

You may not be sharing enough! 

Multi-task learning <-> a form of regularization 
<font color='green'>Solution</font>: Share more.

### 7.3 What if you have a lot of tasks?

Should you train all of them together? Which ones will be complementary?

<font color='red'>The bad news</font>: No closed-form solution for measuring task similarity.
ç›®å‰æ²¡æœ‰å¥½çš„åŠæ³•åˆ¤æ–­å“ªäº›ä»»åŠ¡é€‚åˆä¸€èµ·è®­ç»ƒ

<font color='green'>The good news</font>: There are ways to approximate it from one training run.
ä½†æ˜¯æˆ‘ä»¬å¯ä»¥è®­ç»ƒå‡ æ­¥è¯•è¯•ç»“æœï¼ˆzeiäº†ï¼Œå°±æ˜¯Finnè‡ªå·±çš„è®ºæ–‡ï¼‰

![600](../../../../../../Attachments/4.%20Artificial%20intelligence/1.%20Major%20goals/Intelligence/Machine%20learning/General%20Multi-Task%20Learning/Special%20Multi-Task%20Learning/Efficiently%20Identifying%20Task%20Groupings%20for%20Multi-Task%20Learning.png)
Fifty, Amid, Zhao, Yu, Anil, Finn. *Efficiently Identifying Task Groupings for Multi-Task Learning.* 2021

## 8. Case study

### Stanford case

![](../../../../../../Attachments/4.%20Artificial%20intelligence/1.%20Major%20goals/Intelligence/Machine%20learning/General%20Multi-Task%20Learning/Special%20Multi-Task%20Learning/cs330_multitask_transfer_2021.pdf#page=27)

### Other works

#### [MMoE](+Papers/MMoE.md)

#### [PLE](+Papers/PLE.md)

## 9. External Resources

[ç‹­ä¹‰å¤šä»»åŠ¡å­¦ä¹ GitHubæ±‡æ€»](https://github.com/Manchery/awesome-multi-task-learning)
