


主要还是用[多任务学习模型](../../1.%20Major%20goals/Intelligence/Machine%20learning/General%20Multi-Task%20Learning/Special%20Multi-Task%20Learning/Special%20multi-task%20learning.md)

我们常见的多任务模型升级路线是Share-Bottom -> MMoE ->CGC/PLE

MMoE为了解决相关性较差的多任务联合训练，PLE引入专有expert降低跷跷板效应

[Mixture-of-Experts (MoE) 经典论文一览](https://zhuanlan.zhihu.com/p/542465517)