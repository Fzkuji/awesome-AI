*此概念解释大部分生成于ChatGPT*

A knowledge-intensive task is a task that requires a high level of knowledge, expertise, and skill to complete. These tasks typically involve problem-solving, decision-making, and critical thinking, and often require a deep understanding of a particular domain or subject matter. Examples of knowledge-intensive tasks include scientific research, engineering design, financial analysis, software development, and strategic planning.
知识密集型任务是需要高水平的知识、专业知识和技能才能完成的任务。 这些任务通常涉及解决问题、决策制定和批判性思维，并且通常需要对特定领域或主题有深刻的理解。 知识密集型任务的示例包括科学研究、工程设计、财务分析、软件开发和战略规划。

In general, knowledge-intensive tasks tend to be more complex and difficult to automate than routine or manual tasks, as they require the ability to understand and interpret complex information, apply judgment and reasoning, and adapt to changing circumstances. These tasks are often performed by highly skilled professionals and are critical to the success of many organizations and industries.
一般来说，知识密集型任务往往比例行或手动任务更复杂，更难实现自动化，因为它们需要理解和解释复杂信息、运用判断和推理以及适应不断变化的环境的能力。 这些任务通常由技能高超的专业人员执行，对许多组织和行业的成功至关重要。

> [KILT (Knowledge Intensive Language Tasks)](https://ai.facebook.com/tools/kilt) is a new unified benchmark to help AI researchers build models that are better able to leverage real-world knowledge to accomplish a broad range of tasks.
> 
> It unifies [11 widely used public datasets](https://evalai.cloudcv.org/web/challenges/challenge-page/689/phases?fbclid=IwAR0f7OsY-14YCUjbvnQ0jDWfpIr2O7Y5UCRg6opiDxAmNYO2eszk6SLwOjg) representing five different types of tasks: fact-checking, open-domain question answering, slot filling, entity linking, and dialog generation. KILT is the first benchmark that aggregates datasets representing such a wide variety of knowledge-intensive tasks.
> 
> All the datasets in KILT are aligned with a single knowledge source: a recent snapshot of Wikipedia. This can help catalyze research into unified, task-agnostic architectures for knowledge-intensive tasks. It also makes it much easier to experiment with different task-specific solutions.
> 
> When evaluating how models perform on knowledge-based tasks, it’s important to consider not just the particular output but also the specific information used to produce it. The KILT benchmark includes provenance information, or the mapping of the correct knowledge that can solve the task. For several tasks, we make the provenance annotation more comprehensive with an annotation campaign. Together, the output and provenance allow researchers to assess a model’s accuracy and its ability to justify a model prediction.
> 
> \- [Meta](https://ai.facebook.com/blog/introducing-kilt-a-new-unified-benchmark-for-knowledge-intensive-nlp-tasks/)


知识密集型任务有：
- [Information retrieval](5.%20Information%20science/Information%20retrieval/Information%20retrieval.md)
- Open-domain question answering (QA)
- Fact checking
- Dialogue generation
- Slot filling
- Entity linking

![Pasted image 20230629163356](Resources/4.%20Artificial%20intelligence/3.%20Applications/Knowledge-intensive%20tasks/Pasted%20image%2020230629163356.png)

