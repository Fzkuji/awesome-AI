Title: Memristors—From In-Memory Computing, Deep Learning Acceleration, and Spiking Neural Networks to the Future of Neuromorphic and Bio-Inspired Computing

## Link
Link: https://onlinelibrary.wiley.com/doi/full/10.1002/aisy.202000085

## Abstract
Machine learning, particularly in the form of deep learning (DL), has driven most of the recent fundamental developments in artificial intelligence (AI). DL is based on computational models that are, to a certain extent, bio-inspired, as they rely on networks of connected simple computing units operating in parallel. The success of DL is supported by three factors: availability of vast amounts of data, continuous growth in computing power, and algorithmic innovations. The approaching demise of Moore's law, and the consequent expected modest improvements in computing power that can be achieved by scaling, raises the question of whether the progress will be slowed or halted due to hardware limitations. This article reviews the case for a novel beyond-complementary metal–oxide–semiconductor (CMOS) technology—memristors—as a potential solution for the implementation of power-efficient in-memory computing, DL accelerators, and spiking neural networks. Central themes are the reliance on non-von-Neumann computing architectures and the need for developing tailored learning and inference algorithms. To argue that lessons from biology can be useful in providing directions for further progress in AI, an example-based reservoir computing is briefly discussed. At the end, speculation is given on the “big picture” view of future neuromorphic and brain-inspired computing systems.

深度学习的成功得益于三个因素：海量数据的可用性、计算能力的持续增长和算法创新。本文回顾了一种新颖的超互补金属氧化物半导体 (CMOS) 技术——忆阻器——作为实现高能效内存计算、DL 加速器和尖峰神经网络的潜在解决方案的案例。中心主题是对非冯诺依曼计算架构的依赖以及开发定制学习和推理算法的需求。 为了证明生物学的教训可以为人工智能的进一步发展提供方向，我们简要讨论了基于示例的储层计算。 最后，对未来神经形态和类脑计算系统的“全局”视图进行了推测。


## 概述
文章貌似使用CMOS的硬件去设计模拟人的神经元结构，其担忧是目前硬件发展放缓，计算速度收到硬件限制。Memristor被翻译为忆阻器。

但个人目前（2022）认为忆阻器可能是解决人工智能基础结构的方案，但最终形成AI还要取决于算法。

忆阻器介绍：
https://www.bilibili.com/video/BV16Y4y1J7NU