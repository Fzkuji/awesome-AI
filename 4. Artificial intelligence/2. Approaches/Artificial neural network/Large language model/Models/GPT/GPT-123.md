# GPT
## Abstract

在NLP中，有标签的数据很少，无标签的数据很多。因此，GPT尝试用无标签数据去预训练一个语言模型。之后可以用标好的数据做一个语言模型。

- NLP领域一直没有预训练模型的原因是没有庞大的标好的数据集，CV领域的[ImageNet](https://www.image-net.org/)这样的数据集都是有标签的，所以才方便预训练。
- 而BERT、GPT这样的模型终于在NLP领域进行了一个突破，使得无标签预训练模型成为可能
- GPT之后的衍生版本引入了[ Zero-shot learning](https://en.wikipedia.org/wiki/Zero-shot_learning)又是另一个突破

挑战：
- 优化目标不好找，也就是损失函数不好定，容易出现在部分任务上好但是其他任务上不行的情况
- 另一个是如何将学习到的信息传递给下游任务，下游任务的形式是多样的

## Methods

### Architecture
主要解决方案是自监督学习（大概也可以划分为半监督学习方法）

模型使用了[Transformer](https://en.wikipedia.org/wiki/Transformer_(machine_learning_model))架构，Transformer在迁移学习任务中比RNN更加稳健，能够处理更长的文本信息。同时模型只使用Transformer的解码器部分（因为解码器部分使用了掩码，可以避免模型看到未来的文本信息，因此任务相当于续写；而BERT使用了Transformer的编码器部分，导致其相当于完形填空。显然前者难度更高）

### Fine-tuning
微调包含了两类损失函数，一个是自监督的损失函数，另一种是给下游任务设计的专门的损失函数。

### 特定于任务的输入转换
^8a6202

下游任务的输入是千变万化的，如何解决不同任务的需求、设计一个**统一的输入格式**就是第三小节要解决的问题。

GPT针对不同的任务，将输入进行了不同的变换操作。

![156](../../../../../../Attachments/4.%20Artificial%20intelligence/2.%20Approaches/Artificial%20neural%20network/Large%20language%20model/Transformer%20architecture%20and%20training%20objectives%20used%20in%20GPT.png) ![600](../../../../../../Attachments/4.%20Artificial%20intelligence/2.%20Approaches/Artificial%20neural%20network/Large%20language%20model/Input%20transformations%20for%20fine-tuning%20on%20different%20tasks.png)
Figure 1: (left) Transformer architecture and training objectives used in this work. (right) Input transformations for fine-tuning on different tasks. We convert all structured inputs into token sequences to be processed by our pre-trained model, followed by a linear+softmax layer.

分类问题：
- 在文本前后加上词元（Start、Extract），然后整体放入模型（Transformer）中。在微调阶段，需要在预训练模型后添加一个线性层，因为要分类，就当作softmax使用。

蕴含问题：
- 蕴含问题其实就是[Implication](../../../../../../Attachments/0.%20Philosophy/Implication.pdf)，相当于让模型去验证文本的逻辑关系。
- 训练中将前提和假设用词元连接，然后将整个文本输入模型。最后同样加入一个线性层，判断前提是否与假设一致，本质上也就是一个三分类问题。

相似问题：
- 大概就是问两个表述是否等价
- 等价在逻辑上可以理解为a对b存在一个关系，b对a也存在这个关系。
- 模型将两个表述一前一后连接起来，输入到模型中，最后比较两个结果是否一致，又变成了二分类问题

多选题：
- 就像平时做的多选题一样，有多个选项，需要选出那个最正确的
- 方法就是每个结果都和题目进行匹配然后输入模型，最后在额外的线性层判断哪个概率最大

通过这些设计，可以完整的保留预训练Transformer的结构，不需要因为后续任务而做出调整
## Experiments
### Dataset

[BookCorpus](https://github.com/soskek/bookcorpus) - 7000篇没有被发表的书
### Model structure

12层的Transformer的解码器，每一层的维度时768（和BERT_base的大小一样），最终参数约为110M

BERT_large的参数是BERT_base的三倍，330M。
# GPT-2

因为谷歌出了BERT，因此

与前代相比
- 更大的数据集WebText，更大的模型（1.5B参数量）。
- 加了新卖点——Zero-shot

## Methods

### Prompt

如何实现不需要微调的模型呢？那就是取消所有[](.md#^8a6202%7C%E7%89%B9%E5%AE%9A%E4%BA%8E%E4%BB%BB%E5%8A%A1%E7%9A%84%E8%BE%93%E5%85%A5%E8%BD%AC%E6%8D%A2)，直接将任务表述成语言。
比如，如果想要将一段英语翻译成法语，那么就直接输入："翻译这段话+英文"，最后的Label是法文，最后这个方法就叫做提示——[Prompting](4.%20Artificial%20intelligence/2.%20Approaches/Artificial%20neural%20network/Large%20language%20model/Prompting.md)

Prompt主要目标就是让模型输出想要的答案，并且训练的时候也会提供这样的格式进行训练。最终也会相应地更新参数。

### Temperature

```
>>> import torch
>>> import torch.nn.functional as F
>>> a = torch.tensor([1,2,3,4.])
>>> F. softmax(a, dim=0)
tensor([0.0321, 0.0871, 0.2369, 0.6439])
>>> F. softmax(a/.5, dim=0)
tensor([0.0021, 0.0158, 0.1171, 0.8650])
>>> F.softmax(a/1.5, dim=0)
tensor([0.0708, 0.1378, 0.2685, 0.5229])
>>> F.softmax(a/1e-6, dim=0)
tensor([0., 0., 0., 1.])
```

其中，温度就是a这个概率分布除以的数字（0.5/1/1.5），而这个操作是在softmax之前，因此看可以改变最终softmax的结果。

- 温度就是对预测结果进行概率重新设计
- 默认温度为1就相当于还是softmax
- 默认温度越高 多样性就越丰富
- 默认温度越低相当于越希望得到最准的那一个结果

### Top-k & Top-p

Top-k指选择前k个概率最高的结果

Top-p指选择多个结果，其概率累加之和可以达到p这个值（一般为0.9/0.95）

## Experiments
### Dataset

[Common Crawl](https://commoncrawl.org/)，用爬虫项目的网页，最终用的是reddit上点赞高于3的言论

## Conclusion

最后就是功能强大，但是还是比专用的模型差一点。
# GPT-3
Generative Pre-trained Transformer 3 是一种自回归语言模型，它使用深度学习来生成类似人类的文本。给定初始文本作为提示，它将生成继续提示的文本。

## Methods
### Meta-learning

本文在GPT-2的基础上测试了Zero-shot、One-shot和Few-shot的不同性能。

**这里的Meta-learning和通常上说的不太一样，这里的Zero-shot、One-shot和Few-shot learning都不会对模型进行参数更新，而仅仅给模型一些额外的信息辅助预测。但是这样的信息并不属于Prompt，Prompt的主要目标是引导模型做出相应的回复，而Meta-learning是为了让模型预测的更好。**

Zero-shot、One-shot和Few-shot的区别在于用多少数据。Zero-shot就是一个都不用，Few-shot就是每个任务用几十个。

#### Zero-shot
The model predicts the answer given only a natural language description of the task. No gradient updates are performed.

```
Translate English to French:        <- task description
cheese =>                           <- prompt
```

#### One-shot
In addition to the task description, the model sees a single example of the task. No gradient updates are performed.

```
Translate English to French:        <- task description
sea otter => loutre de mer          <- example
cheese =>                           <- prompt
```

#### Few-shot
In addition to the task description, the model sees a few examples of the task. No gradient updates are performed.

```
Translate English to French:        <- task description
sea otter => loutre de mer          <-- examples
peppermint => menthe poivrée        <-╯
plush girafe => girafe peluche      <-╯
cheese =>                           <- prompt
```

## Experiments
### Setups

模型使用了很大的batch。

值得注意的是，实践证明，小模型需要更小的batch，而大模型可以选择很大的batch，甚至不用考虑难以训练的问题，而平时小模型使用大的batch就不好训练了。
可能的原因： ^85edfa
- 大模型的结构可能有优势，比简单的MLP更好
- 或许大的模型可以搜索更多结构的特征，搜索范围更广

另一个问题是，通常的模型batch变大的时候，学习率是要相应增加的，但是GPT中确实往下降的，也是比较特殊。

**这是一个值得研究的课题**

### Dataset

还是[Common Crawl](https://commoncrawl.org/)，但是进行了一些不一样的处理：
- 训练了额外的二分类模型判断数据样本的好坏，GPT-2中reddit的数据作为正样本，其他的作为负样本，最后偏正样本的就用
- lsh算法去重
- 把之前的所有数据都用上

### Training

GPT-3非常难训练，技术要求包括但不限于：
- 分布式训练
- 模型分割
- 数据分割

GPT-3使用了一个V100高带宽GPU集群训练的（DGX-1）

### Test

测试时使用了前面所述的Meta-learning，如果是之前提到的一些任务（分类、多选等），可以用特定的格式，如果不用特定的格式，也可以使用beam search。

### Results

![600](../../../../../../Attachments/4.%20Artificial%20intelligence/2.%20Approaches/Artificial%20neural%20network/Large%20language%20model/损失和计算量的关系图.png)

如图是损失和计算量的关系图，不同的线对应不同大小的模型，黄色的参数量最大。

事实证明，所有模型最优状态都趋近一个直线，但是横坐标是指数增长，但是纵坐标却是线性增长，说明要做到完美需要巨量的投入。

## Limitations

- 长文本生成仍然困难（写一个连贯的小说）
- 由于无法看到当前位置以后的文本，导致预测的时候抓不到重点，或许BERT可以解决这个问题（存疑）
- 学习的东西没有真实的概念
- 贵
- 无法解释
- 说假话


解读网站：
https://dugas.ch/artificial_curiosity/GPT_architecture.html