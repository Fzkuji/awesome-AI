Title: Training a Helpful and Harmless Assistant with Reinforcement Learning from Human Feedback

Link: https://arxiv.org/abs/2204.05862

Code: https://github.com/anthropics/hh-rlhf

Additional information: 

Conclusion: Claude 相比 ChatGPT 更能避免潜在 harmful 的问题，在代码生成略为逊色，通用 Prompt 不分伯仲。从效果上，可能 ChatGPT 功能性更强，而 Claude 更为“无害”（或者说，对社会的潜在负面影响更小），这点从参考论文的标题也有所体现。

## Abstract



## Introduction

### Background



### Problems



### Contributions



## Methods

作者解决问题的方法/算法是什么？是否基于前人的方法？基于了哪些？

  

## Evaluation

作者如何评估自己的方法？实验的setup是什么样的？感兴趣实验数据和结果有哪些？有没有问题或者可以借鉴的地方？

  

## Conclusion

作者给出了哪些结论？哪些是strong conclusions, 哪些又是weak的conclusions（即作者并没有通过实验提供evidence，只在discussion中提到；或实验的数据并没有给出充分的evidence）?

  

## References

(optional) 列出相关性高的文献，以便之后可以继续track下去。




## Appendices

### Appendix A



### Appendix B



## Future work

值得研究的点








