


## Construction of LLM-based Agents


### Brain: Primarily Composed of An LLM

#### Knowledge

##### Pretrain model

- [2023/04] **Learning Distributed Representations of Sentences from Unlabelled Data.** _Felix Hill (University of Cambridge) et al. arXiv._ [[paper](https://arxiv.org/abs/1602.03483)]
	- 




### 从无标注数据中学习句子分布式表示

#### 作者:
- Felix Hill（剑桥大学）
- Kyunghyun Cho（纽约大学）
- Anna Korhonen（剑桥大学）

#### 摘要:
这篇论文系统地比较了多种从无标注数据中学习句子分布式表示的方法。研究发现，最佳方法取决于应用的具体需求：更深、更复杂的模型更适用于监督系统，而浅层的对数线性模型则更适用于使用简单空间距离度量的任务。论文还提出了两种新的无监督表示学习目标，旨在优化训练时间、领域可移植性和性能之间的权衡。

#### 关键点:
1. **分布式表示**:
   - 稠密的实值向量编码语言单元的语义。
   - 对于单词，已经有基于任务无关目标（如预测相邻单词）的成熟方法。
   - 对于短语或句子，目前尚无一致的最佳学习方法。

2. **比较的模型**:
   - **SkipThought 向量**: 使用递归神经网络预测相邻句子。
   - **ParagraphVector (DBOW 和 DM)**: 学习向量以预测句子或上下文中的单词。
   - **CBOW 和 SkipGram**: 单词嵌入通过元素加法组成。
   - **C-PHRASE**: 使用监督解析推断分布式语义表示。
   - **顺序去噪自动编码器 (SDAE)**: 学习从损坏的版本中恢复原始句子。
   - **FastSent**: 使用词袋表示预测相邻句子。

3. **评估**:
   - **监督任务**: 包括复述识别、情感分析、主观性分类等。
   - **无监督任务**: 使用句子向量之间的余弦距离来衡量语义相似性。

4. **研究结果**:
   - 更深的模型（如 SkipThought）在监督评估中表现优异。
   - 浅层模型（如 FastSent）在无监督评估中表现更好。
   - SDAE 在复述识别中表现出色。
   - 词典定义可以作为学习表示的强大资源，DictRep 在各任务中表现稳定。

5. **训练**:
   - 模型在多伦多书籍语料库（包含7000万有序句子）上进行训练。
   - 各模型的训练时间和资源需求差异显著。

6. **结论**:
   - 模型选择取决于应用的具体需求和可用资源。
   - 句子出现的上下文对于理解其语义至关重要。

#### 实践意义:
- **对研究人员**: 研究结果为根据具体需求选择句子表示模型提供了宝贵的指导。
- **对开发人员**: 如 FastSent 和 DictRep 等模型提供了在不同资源约束下将句子表示集成到应用中的实用解决方案。

详情请参阅完整论文 [链接](https://arxiv.org/abs/1602.03483)。