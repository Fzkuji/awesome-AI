### ChatGPT在推理、幻觉和互动性上的多任务、多语言、多模态评估

#### 作者：
- Yejin Bang, Samuel Cahyawijaya, Nayeon Lee, Wenliang Dai, Dan Su, Bryan Wilie, Holy Lovenia, Ziwei Ji, Tiezheng Yu, Willy Chung, Quyet V. Do, Yan Xu, Pascale Fung
- Centre for Artificial Intelligence Research (CAiRE), The Hong Kong University of Science and Technology

#### 摘要：
本文提出了一个定量评估互动大型语言模型（LLMs，如ChatGPT）的框架，使用了23个数据集，涵盖8个常见的NLP应用任务。我们基于这些数据集和一个新设计的多模态数据集，广泛评估了ChatGPT的多任务、多语言和多模态方面的表现。结果显示，ChatGPT在大多数任务中优于零样本学习的LLMs，甚至在某些任务上超越了微调模型。我们发现它在理解非拉丁文字语言方面优于生成这些语言。它能够通过中间代码生成步骤，从文本提示生成多模态内容。此外，我们发现ChatGPT在10种不同推理类别中的平均准确率为63.41%，因此在推理方面不太可靠。与其他LLMs一样，ChatGPT也存在幻觉问题。最后，ChatGPT的互动功能使其能够通过多轮“提示工程”提升其性能，如在摘要任务中提升8%的ROUGE-1分数，在机器翻译任务中提升2%的ChrF++分数。我们发布了一个用于评估集提取的代码。

#### 主要内容：

1. **多任务、多语言和多模态评估**：
   - **多任务能力**：ChatGPT在多个NLP任务上展示了卓越的零样本学习表现，超越了之前的零样本LLMs，并在某些任务上超过了完全微调的模型。
   - **多语言能力**：ChatGPT在处理低资源语言方面表现出局限性，尤其是在非拉丁文字的生成方面表现较差。
   - **多模态能力**：ChatGPT能够通过生成中间代码表示视觉图像，展示出其在视觉理解和推理方面的初步能力。

2. **推理能力评估**：
   - **逻辑推理**：ChatGPT在归纳推理方面表现较弱，但在演绎和溯因推理方面表现较好。
   - **非文本语义推理**：在数学、时间和空间推理任务上，ChatGPT的表现参差不齐。
   - **常识推理**：ChatGPT在常识推理任务上表现出色，可能是由于其大规模的参数记忆。

3. **幻觉问题**：
   - ChatGPT与其他LLMs一样，存在生成不符合事实的幻觉问题。
   - 在某些任务中，如机器翻译和问答，幻觉问题较为明显。

4. **互动性评估**：
   - ChatGPT的多轮对话互动能力使其能够在多个任务中改进生成的响应质量和任务性能。
   - 在摘要和机器翻译任务中，通过多轮提示工程显著提升了性能。

#### 实践意义：
- **研究人员**：提供了一个全面的框架，用于定量评估互动大型语言模型在多个NLP任务上的表现。
- **开发人员**：展示了如何利用ChatGPT的多轮互动功能，通过提示工程改进任务性能。

详情请参阅完整论文 [链接](https://arxiv.org/pdf/2302.04023)。