# 第一次会

![[Pasted image 20230707141807.png]]

大模型量化可以提升模型效率

可不可以用RLHF训练一个模拟用户偏好的的奖励函数？

![[Pasted image 20230707145029.png]]

# 第二次会 2023-7-11

文林的工作：

![[Pasted image 20230711192411.png]]

# 第三次会 2023-7-12

![[Pasted image 20230712144046.png]]



全参数微调（domain embedding（p-tuning v2, lora））+ 

hidden states + attention pooling

prefix tuning, p-tuning (+encoder), p-tuning v2, lora, adapter

cross-domain / multi-domain


cross-domain freeze language model


几个数据集比较合适: 亚马逊

cross-domain至少4个数据

tiny-bert -> bert -> roberta -> chatglmv2

任务：CTR预测

baseline: mmoe, ple, mix, star

数据混合起来训练

