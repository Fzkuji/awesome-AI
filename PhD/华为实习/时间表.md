## Contributions

> Domain embedding first or attention pooling?

### Domain embedding

可选方案：

1. 设计hard prompt，使用[LoRA](https://arxiv.org/abs/2106.09685)全参微调LLM
	- 使用全部场景数据集
	- 将LLM的输出作为domain embedding

2. 使用P-Tuning微调连续提示（continuous prompts）
	- 这些连续提示是可训练的嵌入（embeddings），它们被添加到输入词嵌入的原始序列中。在训练过程中，只有这些连续提示会被更新
	- P-Tuning v2

> P-Tuning v2 or 1?

### Attention pooling

在原本LLM的输出的基础上加入attention pooling：

[64 注意力机制【动手学深度学习v2】](https://www.bilibili.com/video/BV1264y1i7R1/)

可选方案：

1. 无参数attention pooling：
	- $f(x)=\sum_{i=1}^n \frac{K\left(x-x_i\right)}{\sum_{j=1}^n K\left(x-x_j\right)} y_i$
	- 如果使用高斯核 $K(u)=\frac{1}{\sqrt{2 \pi}} \exp \left(-\frac{u^2}{2}\right)$ ，那么$\begin{aligned}	f(x) & =\sum_{i=1}^n \frac{\exp \left(-\frac{1}{2}\left(x-x_i\right)^2\right)}{\sum_{j=1}^n \exp \left(-\frac{1}{2}\left(x-x_j\right)^2\right)} y_i \\& =\sum_{i=1}^n \operatorname{softmax}\left(-\frac{1}{2}\left(x-x_i\right)^2\right) y_i\end{aligned}$

2. 带参数attention pooling：
	- $f(x)=\sum_{i=1}^n \operatorname{softmax}\left(-\frac{1}{2}\left(\left(x-x_i\right) w\right)^2\right) y_i$

> 本实验中应该是选择无参数attention pooling？和domain embedding使用两个不同的LLM？

### Cross-domian MoE

此时，前两部分已经对LLM进行了训练和微调，可以冻结LLM部分，训练最后的MoE部分。

本部分计划使用CGC结构：

![[Pasted image 20230713163957.png|500]]




## Experiments

### Datasets

#### Criteo

This dataset contains feature values and click feedback for millions of display ads. Its purpose is to benchmark algorithms for clickthrough rate (CTR) prediction. 

Criteo广告数据集是一个经典的用于预测广告点击率的数据集。2014年，由全球知名广告公司Criteo赞助举办展示广告挑战赛。但比赛过去太久了，Kaggle已不提供数据集。现有的不同获取数据集样本的方式：

1. 官网
	1. 发布数据集的组织是[Criteo AI Lab](https://ailab.criteo.com/)
	2. 他们发布的所有数据集可以在[这个](https://ailab.criteo.com/ressources/)网页找到
	3. 官网提供的数据集是1TB版本，压缩包大小为342GB，[下载页面](https://labs.criteo.com/2013/12/download-terabyte-click-logs-2/)
2. Kaggle
	1. 官方在kaggle发布的[比赛](https://www.kaggle.com/competitions/criteo-display-ad-challenge)是11GB版本，压缩包大小为4.3GB。但是因为时间太久，数据集已经不开放下载了
	2. 不过有一个[镜像数据集网页](https://www.kaggle.com/datasets/mrkmakr/criteo-dataset)上传在了kaggle上，可以下载
3. 其他
	1. 在GitHub上DeepCTR项目的issues/308讨论中提到了[另一个网站]([https://figshare.com/articles/dataset/Kaggle_Display_Advertising_Challenge_dataset/5732310](https://figshare.com/articles/dataset/Kaggle_Display_Advertising_Challenge_dataset/5732310))，目前也可以11GB版本

- criteo数据集用于广告点击率预估任务（标签：0/1），**其中包含13个dense特征和26个sparse特征**
- 数据格式如下：**第一列为label, 之后分别是13个dense特征(integer feature)，26个sparse特征(categorical feature)；每列之间使用tab进行分隔**

信息源：
- https://github.com/ZiyaoGeng/RecLearn/wiki/Criteo-Dataset
- https://github.com/shenweichen/DeepCTR/issues/308
- https://www.jianshu.com/p/5c88f4bd7c71


#### MovieLens


https://grouplens.org/datasets/movielens/


#### [Amazon Review Data (2018)](https://nijianmo.github.io/amazon/index.html)

 > 如何设计CTR任务？感觉缺少用户信息

为了使其适用于CTR（点击率）预测任务，需要将其转化为一个二分类的数据。原始的用户对物品的评分是一个从0到5的连续值。我们将评分为4和5的样本标记为正样本，其余的标记为负样本。

任务是基于用户的历史行为来预测用户是否会给定的电影评分超过3（标记为正）。

特征包括
- reviewerID - ID of the reviewer, e.g. [A2SUAM1J3GNN3B](http://www.amazon.com/gp/cdp/member-reviews/A2SUAM1J3GNN3B)
- asin - ID of the product, e.g. [0000013714](http://www.amazon.com/dp/0000013714)
- reviewerName - name of the reviewer
- vote - helpful votes of the review
- style - a disctionary of the product metadata, e.g., "Format" is "Hardcover"
- reviewText - text of the review
- overall - rating of the product
- summary - summary of the review
- unixReviewTime - time of the review (unix time)
- reviewTime - time of the review (raw)
- image - images that users post after they have received the product


### Timestamps

如果没有别的活的话：

| Date        | Plan                                                           |
| ----------- | -------------------------------------------------------------- |
|             | related works gathering (optional）                            |
| 7.17 - 7.23 | environment setup & dataset preparation                        |
| 7.24 - 7.30 | base model coding & test                                       |
| 7.31 - 8.6  | base model training & result recording & baselines preparation |
| 8.7 - 8.13  | replace LoRA with P-tuning & result recording                  |
| 8.14 - 8.20 | change to bigger models & baseline training & result recording | 

| 日期        | 计划                                                           |
| ----------- | -------------------------------------------------------------- |
|             | 收集相关工作（可选）                            |
| 7.17 - 7.23 | 环境设置和数据集准备                        |
| 7.24 - 7.30 | 基础模型编码和测试                                       |
| 7.31 - 8.6  | 基础模型训练 & 结果记录 & 基线准备 |
| 8.7 - 8.13  | 用P-tuning替换LoRA & 结果记录                  |
| 8.14 - 8.20 | 切换到更大的模型 & 基线训练 & 结果记录 | 

